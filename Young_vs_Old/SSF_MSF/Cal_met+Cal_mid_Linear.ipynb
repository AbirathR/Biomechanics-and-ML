{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPmwKuzy1JRvx9esETSf+OC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HpvB6Oxcnm59"},"source":["# **Mounting Google Drive**"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive"],"metadata":{"id":"26yaaUCAxgc4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663862445838,"user_tz":180,"elapsed":20925,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"e2a23bbd-5489-48de-e0ae-ea9f116433bd"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n","/gdrive\n"]}]},{"cell_type":"code","source":["import os\n","os.getcwd()"],"metadata":{"id":"gnQjqn3px5l_","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1663862445838,"user_tz":180,"elapsed":6,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"19ba1b12-ad0f-4d52-b0d8-957604c723f6"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/gdrive'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"rd32VN7-onqw"},"source":["#### Move to the Dataset Dircetory in My Drive"]},{"cell_type":"code","source":["os.chdir(\"/gdrive/MyDrive/Autism_code/Young_vs_Old/SSF_MSF\")\n","!pwd"],"metadata":{"id":"_xOjnotEx65u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663862447101,"user_tz":180,"elapsed":1267,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"8d14ac86-6915-48bf-e82b-fd0f66481f7b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/gdrive/MyDrive/Autism_code/Young_vs_Old/SSF_MSF\n"]}]},{"cell_type":"code","source":["# importing necessary packages\n","import matplotlib.pyplot as plt  # for making plots / graphs\n","import pandas as pd              # for reading the .csv file and related operations\n","import numpy as np               # for working with arrays (multi-dimensional)  \n","\n","# read the dataset\n","df = pd.read_csv(\"./TS_Kinematics_SSF_MSF_Planar_dataset_2022-reduced_vars.csv\")\n","\n","# now, the whole dataset csv dataset file is saved into `df` variable.\n","print(\"df.shape = \", df.shape)\n","df.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289},"id":"q8w-NuGrbwUd","executionInfo":{"status":"ok","timestamp":1663862448902,"user_tz":180,"elapsed":1803,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"f1936ede-77f7-430e-94d8-498a4a32fefc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["df.shape =  (72, 260)\n"]},{"output_type":"execute_result","data":{"text/plain":["  Participant Age group Processed speed SIDE  Cycle_Time_Mean  \\\n","0        P001         Y               N    L            1.135   \n","1        P001         Y               N    R            1.135   \n","2        P002         Y               N    L            0.985   \n","\n","   Step_Length_Mean     Speed  Double_Limb_Support_Time_Ave  \\\n","0          0.682212  1.246092                         0.260   \n","1          0.732050  1.246092                         0.260   \n","2          0.701486  1.412893                         0.135   \n","\n","   Single Support Time  Time to TO  ...  Max Stance_S2G  TimeMax Stance_S2G  \\\n","0                0.440        0.70  ...       85.003563           59.649124   \n","1                0.435        0.70  ...       85.173409           60.176991   \n","2                0.420        0.56  ...       91.685211           57.142849   \n","\n","   Min Stance_S2V  TimeMin Stance_S2V  Max Stance_S2V  TimeMax Stance_S2V  \\\n","0      -10.577213            2.631576        7.834396           38.596493   \n","1       -6.651151            2.654886        6.187871           44.247780   \n","2       -6.316910            0.000000        9.186202           53.061218   \n","\n","   Min Stance_V2G  TimeMin Stance_V2G  Max Stance_V2G  TimeMax Stance_V2G  \n","0      -19.257086                   0       74.823166           61.403507  \n","1      -17.311865                   0       75.929893           61.946899  \n","2      -12.266258                   0       55.614689           57.142849  \n","\n","[3 rows x 260 columns]"],"text/html":["\n","  <div id=\"df-867a7ba9-0132-49ed-8470-7c986b10de6b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Participant</th>\n","      <th>Age group</th>\n","      <th>Processed speed</th>\n","      <th>SIDE</th>\n","      <th>Cycle_Time_Mean</th>\n","      <th>Step_Length_Mean</th>\n","      <th>Speed</th>\n","      <th>Double_Limb_Support_Time_Ave</th>\n","      <th>Single Support Time</th>\n","      <th>Time to TO</th>\n","      <th>...</th>\n","      <th>Max Stance_S2G</th>\n","      <th>TimeMax Stance_S2G</th>\n","      <th>Min Stance_S2V</th>\n","      <th>TimeMin Stance_S2V</th>\n","      <th>Max Stance_S2V</th>\n","      <th>TimeMax Stance_S2V</th>\n","      <th>Min Stance_V2G</th>\n","      <th>TimeMin Stance_V2G</th>\n","      <th>Max Stance_V2G</th>\n","      <th>TimeMax Stance_V2G</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>P001</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>L</td>\n","      <td>1.135</td>\n","      <td>0.682212</td>\n","      <td>1.246092</td>\n","      <td>0.260</td>\n","      <td>0.440</td>\n","      <td>0.70</td>\n","      <td>...</td>\n","      <td>85.003563</td>\n","      <td>59.649124</td>\n","      <td>-10.577213</td>\n","      <td>2.631576</td>\n","      <td>7.834396</td>\n","      <td>38.596493</td>\n","      <td>-19.257086</td>\n","      <td>0</td>\n","      <td>74.823166</td>\n","      <td>61.403507</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>P001</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>R</td>\n","      <td>1.135</td>\n","      <td>0.732050</td>\n","      <td>1.246092</td>\n","      <td>0.260</td>\n","      <td>0.435</td>\n","      <td>0.70</td>\n","      <td>...</td>\n","      <td>85.173409</td>\n","      <td>60.176991</td>\n","      <td>-6.651151</td>\n","      <td>2.654886</td>\n","      <td>6.187871</td>\n","      <td>44.247780</td>\n","      <td>-17.311865</td>\n","      <td>0</td>\n","      <td>75.929893</td>\n","      <td>61.946899</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>P002</td>\n","      <td>Y</td>\n","      <td>N</td>\n","      <td>L</td>\n","      <td>0.985</td>\n","      <td>0.701486</td>\n","      <td>1.412893</td>\n","      <td>0.135</td>\n","      <td>0.420</td>\n","      <td>0.56</td>\n","      <td>...</td>\n","      <td>91.685211</td>\n","      <td>57.142849</td>\n","      <td>-6.316910</td>\n","      <td>0.000000</td>\n","      <td>9.186202</td>\n","      <td>53.061218</td>\n","      <td>-12.266258</td>\n","      <td>0</td>\n","      <td>55.614689</td>\n","      <td>57.142849</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows × 260 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-867a7ba9-0132-49ed-8470-7c986b10de6b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-867a7ba9-0132-49ed-8470-7c986b10de6b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-867a7ba9-0132-49ed-8470-7c986b10de6b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# print the columns of the data frame\n","print(df.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mhJCBiRQbwQV","executionInfo":{"status":"ok","timestamp":1663862448902,"user_tz":180,"elapsed":12,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"ec95ee06-2a78-4b00-a898-8136caf700f9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['Participant', 'Age group', 'Processed speed', 'SIDE',\n","       'Cycle_Time_Mean', 'Step_Length_Mean', 'Speed',\n","       'Double_Limb_Support_Time_Ave', 'Single Support Time', 'Time to TO',\n","       ...\n","       'Max Stance_S2G', 'TimeMax Stance_S2G', 'Min Stance_S2V',\n","       'TimeMin Stance_S2V', 'Max Stance_S2V', 'TimeMax Stance_S2V',\n","       'Min Stance_V2G', 'TimeMin Stance_V2G', 'Max Stance_V2G',\n","       'TimeMax Stance_V2G'],\n","      dtype='object', length=260)\n"]}]},{"cell_type":"code","source":["# Remove unwanted columns- columns not needed for this analysis.\n","# dropping \"Collected Speed\", \"Dimensionless Speed\", "],"metadata":{"id":"pkeftvQIzfFV","executionInfo":{"status":"ok","timestamp":1663862448902,"user_tz":180,"elapsed":10,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["df_Cal_Met_cols = df.loc[:, 'Min Stance_Cal_Met_X' : 'TimeMax Swing_Cal_Met_Z'].columns.values\n","df_Cal_Mid_cols = df.loc[:, 'Min Stance_Cal_Mid_X' : 'TimeMax Swing_Cal_Mid_Z'].columns.values"],"metadata":{"id":"zG6tWi5ZD-0m","executionInfo":{"status":"ok","timestamp":1663862448902,"user_tz":180,"elapsed":9,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["print(\"df_Cal_Met_cols.shape = \", df_Cal_Met_cols.shape)\n","print(\"df_Cal_Mid_cols.shape = \", df_Cal_Mid_cols.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gGKccVOvEZHd","executionInfo":{"status":"ok","timestamp":1663862448903,"user_tz":180,"elapsed":10,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"e5e5a6d2-f4e2-4b99-831b-f648d5a15abd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["df_Cal_Met_cols.shape =  (24,)\n","df_Cal_Mid_cols.shape =  (24,)\n"]}]},{"cell_type":"code","source":["df_Cal_Met_Cal_Mid_cols = np.append(df_Cal_Met_cols, df_Cal_Mid_cols)\n","print(\"df_Cal_Met_Cal_Mid_cols.shape = \", df_Cal_Met_Cal_Mid_cols.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYqylyTPEnb9","executionInfo":{"status":"ok","timestamp":1663862448903,"user_tz":180,"elapsed":9,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"51b6e677-442b-4f4d-89d3-74b18dafb0c0"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["df_Cal_Met_Cal_Mid_cols.shape =  (48,)\n"]}]},{"cell_type":"code","source":["# Remove the Columns: [\"Participant\", \"Side\"]- These columns were not needed.\n","df = df.drop([\"Participant\", \"SIDE\", \"Processed speed\"], axis=1)\n","print(\"df.shape = \", df.shape)\n","df.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3HhJQHf1bwMQ","executionInfo":{"status":"ok","timestamp":1663862448903,"user_tz":180,"elapsed":8,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"1e5f87c4-6e2e-49b9-d773-6e6e545804ea"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["df.shape =  (72, 257)\n"]},{"output_type":"execute_result","data":{"text/plain":["Index(['Age group', 'Cycle_Time_Mean', 'Step_Length_Mean', 'Speed',\n","       'Double_Limb_Support_Time_Ave', 'Single Support Time', 'Time to TO',\n","       'Steps_Per_Minute_Mean', 'Stride_Length_Mean', 'Min Stance_Pelv_X',\n","       ...\n","       'Max Stance_S2G', 'TimeMax Stance_S2G', 'Min Stance_S2V',\n","       'TimeMin Stance_S2V', 'Max Stance_S2V', 'TimeMax Stance_S2V',\n","       'Min Stance_V2G', 'TimeMin Stance_V2G', 'Max Stance_V2G',\n","       'TimeMax Stance_V2G'],\n","      dtype='object', length=257)"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["### Label encode target variable - `y`"],"metadata":{"id":"IAZ8y0XbGd7p"}},{"cell_type":"code","source":["# First, look at the target variable\n","print(df.loc[:, \"Age group\"].values.shape)\n","print(df.loc[:, \"Age group\"].values)"],"metadata":{"id":"9X3t72ywGN9_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663862449438,"user_tz":180,"elapsed":541,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"9c5796e2-c646-4b23-8273-4ec6a7cd5526"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["(72,)\n","['Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n"," 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'O' 'O' 'O' 'O' 'O' 'O'\n"," 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n"," 'O' 'O' 'O' 'O' 'O' 'O' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'O' 'O' 'O' 'O' 'O' 'O']\n"]}]},{"cell_type":"code","source":["# Perform Data Preprocessing\n","# Label Encoding the class variables \n","# Here, we replace the \"Control\" and \"Autism\" keywords with 0 and 1 values, respectively.\n","df[\"Age group\"] = df[\"Age group\"].replace({'O': 0, 'Y': 1})\n","df.head(3)"],"metadata":{"id":"8xBnH2lKQCvN","colab":{"base_uri":"https://localhost:8080/","height":271},"executionInfo":{"status":"ok","timestamp":1663862449438,"user_tz":180,"elapsed":6,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"50711c83-0343-48ce-b339-86e028db7bd4"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Age group  Cycle_Time_Mean  Step_Length_Mean     Speed  \\\n","0          1            1.135          0.682212  1.246092   \n","1          1            1.135          0.732050  1.246092   \n","2          1            0.985          0.701486  1.412893   \n","\n","   Double_Limb_Support_Time_Ave  Single Support Time  Time to TO  \\\n","0                         0.260                0.440        0.70   \n","1                         0.260                0.435        0.70   \n","2                         0.135                0.420        0.56   \n","\n","   Steps_Per_Minute_Mean  Stride_Length_Mean  Min Stance_Pelv_X  ...  \\\n","0             105.263123            1.410565           2.361861  ...   \n","1             106.203018            1.418065           2.095112  ...   \n","2             122.448975            1.378637           3.227882  ...   \n","\n","   Max Stance_S2G  TimeMax Stance_S2G  Min Stance_S2V  TimeMin Stance_S2V  \\\n","0       85.003563           59.649124      -10.577213            2.631576   \n","1       85.173409           60.176991       -6.651151            2.654886   \n","2       91.685211           57.142849       -6.316910            0.000000   \n","\n","   Max Stance_S2V  TimeMax Stance_S2V  Min Stance_V2G  TimeMin Stance_V2G  \\\n","0        7.834396           38.596493      -19.257086                   0   \n","1        6.187871           44.247780      -17.311865                   0   \n","2        9.186202           53.061218      -12.266258                   0   \n","\n","   Max Stance_V2G  TimeMax Stance_V2G  \n","0       74.823166           61.403507  \n","1       75.929893           61.946899  \n","2       55.614689           57.142849  \n","\n","[3 rows x 257 columns]"],"text/html":["\n","  <div id=\"df-d88128e4-f757-4136-a198-a34178d65b86\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age group</th>\n","      <th>Cycle_Time_Mean</th>\n","      <th>Step_Length_Mean</th>\n","      <th>Speed</th>\n","      <th>Double_Limb_Support_Time_Ave</th>\n","      <th>Single Support Time</th>\n","      <th>Time to TO</th>\n","      <th>Steps_Per_Minute_Mean</th>\n","      <th>Stride_Length_Mean</th>\n","      <th>Min Stance_Pelv_X</th>\n","      <th>...</th>\n","      <th>Max Stance_S2G</th>\n","      <th>TimeMax Stance_S2G</th>\n","      <th>Min Stance_S2V</th>\n","      <th>TimeMin Stance_S2V</th>\n","      <th>Max Stance_S2V</th>\n","      <th>TimeMax Stance_S2V</th>\n","      <th>Min Stance_V2G</th>\n","      <th>TimeMin Stance_V2G</th>\n","      <th>Max Stance_V2G</th>\n","      <th>TimeMax Stance_V2G</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1.135</td>\n","      <td>0.682212</td>\n","      <td>1.246092</td>\n","      <td>0.260</td>\n","      <td>0.440</td>\n","      <td>0.70</td>\n","      <td>105.263123</td>\n","      <td>1.410565</td>\n","      <td>2.361861</td>\n","      <td>...</td>\n","      <td>85.003563</td>\n","      <td>59.649124</td>\n","      <td>-10.577213</td>\n","      <td>2.631576</td>\n","      <td>7.834396</td>\n","      <td>38.596493</td>\n","      <td>-19.257086</td>\n","      <td>0</td>\n","      <td>74.823166</td>\n","      <td>61.403507</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1.135</td>\n","      <td>0.732050</td>\n","      <td>1.246092</td>\n","      <td>0.260</td>\n","      <td>0.435</td>\n","      <td>0.70</td>\n","      <td>106.203018</td>\n","      <td>1.418065</td>\n","      <td>2.095112</td>\n","      <td>...</td>\n","      <td>85.173409</td>\n","      <td>60.176991</td>\n","      <td>-6.651151</td>\n","      <td>2.654886</td>\n","      <td>6.187871</td>\n","      <td>44.247780</td>\n","      <td>-17.311865</td>\n","      <td>0</td>\n","      <td>75.929893</td>\n","      <td>61.946899</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0.985</td>\n","      <td>0.701486</td>\n","      <td>1.412893</td>\n","      <td>0.135</td>\n","      <td>0.420</td>\n","      <td>0.56</td>\n","      <td>122.448975</td>\n","      <td>1.378637</td>\n","      <td>3.227882</td>\n","      <td>...</td>\n","      <td>91.685211</td>\n","      <td>57.142849</td>\n","      <td>-6.316910</td>\n","      <td>0.000000</td>\n","      <td>9.186202</td>\n","      <td>53.061218</td>\n","      <td>-12.266258</td>\n","      <td>0</td>\n","      <td>55.614689</td>\n","      <td>57.142849</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows × 257 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d88128e4-f757-4136-a198-a34178d65b86')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d88128e4-f757-4136-a198-a34178d65b86 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d88128e4-f757-4136-a198-a34178d65b86');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# saving the target variables into `y` variable.\n","y = df.loc[:, \"Age group\"].values\n","print(\"y.shape = \", y.shape)\n","print(\"y = \", y)"],"metadata":{"id":"UCCJC0V_PaEm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663862449438,"user_tz":180,"elapsed":5,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"4692f188-5f4f-471e-e6b1-d1e080c6b804"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["y.shape =  (72,)\n","y =  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0]\n"]}]},{"cell_type":"code","source":["# Perform Data Preprocessing- Data Standardization\n","# Defining a Standard Scaler for scaling the values in the dataset\n","# in the range of [-a, +a], i.e. scale values to a smaller range.\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()"],"metadata":{"id":"XhVuQF0SFXro","executionInfo":{"status":"ok","timestamp":1663862449732,"user_tz":180,"elapsed":297,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"YJo8W22xA9u4","executionInfo":{"status":"ok","timestamp":1663862449733,"user_tz":180,"elapsed":3,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b4c90e4c-fbd0-4972-868d-13c0df7f337a"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(72, 257)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"RKaT_6lfkDZ9","executionInfo":{"status":"ok","timestamp":1663862449733,"user_tz":180,"elapsed":2,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"source":["# Define the different segments from dataset to be used.\n","segments = {\n","    # 'MSF': df.loc[:,'Min Stance_Cal_Met_X' : 'TimeMax Swing_Sha_Cal_Z'],\n","    # 'SSF' : df.loc[:,'Min_Stance_Sha_Foot_X' : 'TimeMax Swing_Sha_Foot_Z']\n","    # 'cal_mid' : df.loc[:,'Min Stance_Cal_Mid_X':'TimeMax Swing_Cal_Mid_Z'],\n","    # 'Mid_met' : df.loc[:,'Min Stance_Mid_Met_X':'TimeMax Swing_Mid_Met_Z']\n","    'Cal_Met_Cal_Mid' : df.loc[:, df_Cal_Met_Cal_Mid_cols]\n","}"],"execution_count":16,"outputs":[]},{"cell_type":"code","source":["print(segments['Cal_Met_Cal_Mid'].shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ncExNYhuFYHh","executionInfo":{"status":"ok","timestamp":1663862450017,"user_tz":180,"elapsed":7,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"6cdcde25-32c0-4ecb-d5e6-d71c17c28008"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["(72, 48)\n"]}]},{"cell_type":"code","source":["segments['Cal_Met_Cal_Mid'].head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"XU5pjBDjFbKl","executionInfo":{"status":"ok","timestamp":1663862450017,"user_tz":180,"elapsed":6,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"cbd8d19e-38b1-4eb6-e0df-c27e570d0838"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Min Stance_Cal_Met_X  TimeMin Stance_Cal_Met_X  Max Stance_Cal_Met_X  \\\n","0            -54.026958                 61.403507            -35.202721   \n","1            -56.390499                 61.674011            -38.140205   \n","2            -57.696159                 57.142849            -44.452549   \n","3            -47.870407                 56.565655            -29.118155   \n","4            -40.664665                 58.823544            -25.658703   \n","\n","   TimeMax Stance_Cal_Met_X  Min Swing_Cal_Met_X  TimeMin Swing_Cal_Met_X  \\\n","0                 49.999992           -54.026958                61.403507   \n","1                 50.220276           -56.392658                61.674011   \n","2                 44.897938           -61.410961                60.204071   \n","3                 41.414127           -51.179707                59.595955   \n","4                 46.150841           -43.398392                61.538799   \n","\n","   Max Swing_Cal_Met_X  TimeMax Swing_Cal_Met_X  Min Stance_Cal_Met_Y  \\\n","0           -44.811600                83.333328              2.690046   \n","1           -46.994694                85.435318             -2.237977   \n","2           -53.242382                82.653053              8.506367   \n","3           -40.516735                83.838394              7.041844   \n","4           -33.849476                82.793419              3.865908   \n","\n","   TimeMin Stance_Cal_Met_Y  ...  Max Swing_Cal_Mid_Y  \\\n","0                 59.649124  ...            15.548207   \n","1                 59.911900  ...            14.974817   \n","2                 57.142849  ...            30.587400   \n","3                 56.565655  ...            26.770086   \n","4                 58.823544  ...            10.832327   \n","\n","   TimeMax Swing_Cal_Mid_Y  Min Stance_Cal_Mid_Z  TimeMin Stance_Cal_Mid_Z  \\\n","0                61.403507              9.231457                 27.192974   \n","1                82.173958             14.356872                  2.643190   \n","2                59.183662             -8.341793                 38.775494   \n","3                56.565655             -0.155559                 40.404026   \n","4                92.739426              8.962367                 42.544018   \n","\n","   Max Stance_Cal_Mid_Z  TimeMax Stance_Cal_Mid_Z  Min Swing_Cal_Mid_Z  \\\n","0             14.862818                 61.403507            10.427507   \n","1             18.627197                 59.911900            13.036373   \n","2              2.766838                 57.142849            -4.752366   \n","3             10.008702                 56.565655             4.635811   \n","4             12.949678                 58.823544             9.222109   \n","\n","   TimeMin Swing_Cal_Mid_Z  Max Swing_Cal_Mid_Z  TimeMax Swing_Cal_Mid_Z  \n","0                83.333328            14.862818                61.403507  \n","1                74.425705            19.120770                79.054405  \n","2               100.000000             3.910995                59.183662  \n","3                88.888885            11.216873                59.090904  \n","4                94.629166            12.848988                58.823544  \n","\n","[5 rows x 48 columns]"],"text/html":["\n","  <div id=\"df-61a3c208-2ee2-4bf4-a744-3a8039e1a985\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Min Stance_Cal_Met_X</th>\n","      <th>TimeMin Stance_Cal_Met_X</th>\n","      <th>Max Stance_Cal_Met_X</th>\n","      <th>TimeMax Stance_Cal_Met_X</th>\n","      <th>Min Swing_Cal_Met_X</th>\n","      <th>TimeMin Swing_Cal_Met_X</th>\n","      <th>Max Swing_Cal_Met_X</th>\n","      <th>TimeMax Swing_Cal_Met_X</th>\n","      <th>Min Stance_Cal_Met_Y</th>\n","      <th>TimeMin Stance_Cal_Met_Y</th>\n","      <th>...</th>\n","      <th>Max Swing_Cal_Mid_Y</th>\n","      <th>TimeMax Swing_Cal_Mid_Y</th>\n","      <th>Min Stance_Cal_Mid_Z</th>\n","      <th>TimeMin Stance_Cal_Mid_Z</th>\n","      <th>Max Stance_Cal_Mid_Z</th>\n","      <th>TimeMax Stance_Cal_Mid_Z</th>\n","      <th>Min Swing_Cal_Mid_Z</th>\n","      <th>TimeMin Swing_Cal_Mid_Z</th>\n","      <th>Max Swing_Cal_Mid_Z</th>\n","      <th>TimeMax Swing_Cal_Mid_Z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-54.026958</td>\n","      <td>61.403507</td>\n","      <td>-35.202721</td>\n","      <td>49.999992</td>\n","      <td>-54.026958</td>\n","      <td>61.403507</td>\n","      <td>-44.811600</td>\n","      <td>83.333328</td>\n","      <td>2.690046</td>\n","      <td>59.649124</td>\n","      <td>...</td>\n","      <td>15.548207</td>\n","      <td>61.403507</td>\n","      <td>9.231457</td>\n","      <td>27.192974</td>\n","      <td>14.862818</td>\n","      <td>61.403507</td>\n","      <td>10.427507</td>\n","      <td>83.333328</td>\n","      <td>14.862818</td>\n","      <td>61.403507</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-56.390499</td>\n","      <td>61.674011</td>\n","      <td>-38.140205</td>\n","      <td>50.220276</td>\n","      <td>-56.392658</td>\n","      <td>61.674011</td>\n","      <td>-46.994694</td>\n","      <td>85.435318</td>\n","      <td>-2.237977</td>\n","      <td>59.911900</td>\n","      <td>...</td>\n","      <td>14.974817</td>\n","      <td>82.173958</td>\n","      <td>14.356872</td>\n","      <td>2.643190</td>\n","      <td>18.627197</td>\n","      <td>59.911900</td>\n","      <td>13.036373</td>\n","      <td>74.425705</td>\n","      <td>19.120770</td>\n","      <td>79.054405</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-57.696159</td>\n","      <td>57.142849</td>\n","      <td>-44.452549</td>\n","      <td>44.897938</td>\n","      <td>-61.410961</td>\n","      <td>60.204071</td>\n","      <td>-53.242382</td>\n","      <td>82.653053</td>\n","      <td>8.506367</td>\n","      <td>57.142849</td>\n","      <td>...</td>\n","      <td>30.587400</td>\n","      <td>59.183662</td>\n","      <td>-8.341793</td>\n","      <td>38.775494</td>\n","      <td>2.766838</td>\n","      <td>57.142849</td>\n","      <td>-4.752366</td>\n","      <td>100.000000</td>\n","      <td>3.910995</td>\n","      <td>59.183662</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-47.870407</td>\n","      <td>56.565655</td>\n","      <td>-29.118155</td>\n","      <td>41.414127</td>\n","      <td>-51.179707</td>\n","      <td>59.595955</td>\n","      <td>-40.516735</td>\n","      <td>83.838394</td>\n","      <td>7.041844</td>\n","      <td>56.565655</td>\n","      <td>...</td>\n","      <td>26.770086</td>\n","      <td>56.565655</td>\n","      <td>-0.155559</td>\n","      <td>40.404026</td>\n","      <td>10.008702</td>\n","      <td>56.565655</td>\n","      <td>4.635811</td>\n","      <td>88.888885</td>\n","      <td>11.216873</td>\n","      <td>59.090904</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-40.664665</td>\n","      <td>58.823544</td>\n","      <td>-25.658703</td>\n","      <td>46.150841</td>\n","      <td>-43.398392</td>\n","      <td>61.538799</td>\n","      <td>-33.849476</td>\n","      <td>82.793419</td>\n","      <td>3.865908</td>\n","      <td>58.823544</td>\n","      <td>...</td>\n","      <td>10.832327</td>\n","      <td>92.739426</td>\n","      <td>8.962367</td>\n","      <td>42.544018</td>\n","      <td>12.949678</td>\n","      <td>58.823544</td>\n","      <td>9.222109</td>\n","      <td>94.629166</td>\n","      <td>12.848988</td>\n","      <td>58.823544</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 48 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61a3c208-2ee2-4bf4-a744-3a8039e1a985')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-61a3c208-2ee2-4bf4-a744-3a8039e1a985 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-61a3c208-2ee2-4bf4-a744-3a8039e1a985');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"ZldBrEE5kA2L","colab":{"base_uri":"https://localhost:8080/","height":334},"executionInfo":{"status":"ok","timestamp":1663862450318,"user_tz":180,"elapsed":306,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"0a590fdd-09c2-4b75-e1ee-e08eee70e24c"},"source":["print(segments[\"Cal_Met_Cal_Mid\"].shape)\n","segments[\"Cal_Met_Cal_Mid\"].head()"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["(72, 48)\n"]},{"output_type":"execute_result","data":{"text/plain":["   Min Stance_Cal_Met_X  TimeMin Stance_Cal_Met_X  Max Stance_Cal_Met_X  \\\n","0            -54.026958                 61.403507            -35.202721   \n","1            -56.390499                 61.674011            -38.140205   \n","2            -57.696159                 57.142849            -44.452549   \n","3            -47.870407                 56.565655            -29.118155   \n","4            -40.664665                 58.823544            -25.658703   \n","\n","   TimeMax Stance_Cal_Met_X  Min Swing_Cal_Met_X  TimeMin Swing_Cal_Met_X  \\\n","0                 49.999992           -54.026958                61.403507   \n","1                 50.220276           -56.392658                61.674011   \n","2                 44.897938           -61.410961                60.204071   \n","3                 41.414127           -51.179707                59.595955   \n","4                 46.150841           -43.398392                61.538799   \n","\n","   Max Swing_Cal_Met_X  TimeMax Swing_Cal_Met_X  Min Stance_Cal_Met_Y  \\\n","0           -44.811600                83.333328              2.690046   \n","1           -46.994694                85.435318             -2.237977   \n","2           -53.242382                82.653053              8.506367   \n","3           -40.516735                83.838394              7.041844   \n","4           -33.849476                82.793419              3.865908   \n","\n","   TimeMin Stance_Cal_Met_Y  ...  Max Swing_Cal_Mid_Y  \\\n","0                 59.649124  ...            15.548207   \n","1                 59.911900  ...            14.974817   \n","2                 57.142849  ...            30.587400   \n","3                 56.565655  ...            26.770086   \n","4                 58.823544  ...            10.832327   \n","\n","   TimeMax Swing_Cal_Mid_Y  Min Stance_Cal_Mid_Z  TimeMin Stance_Cal_Mid_Z  \\\n","0                61.403507              9.231457                 27.192974   \n","1                82.173958             14.356872                  2.643190   \n","2                59.183662             -8.341793                 38.775494   \n","3                56.565655             -0.155559                 40.404026   \n","4                92.739426              8.962367                 42.544018   \n","\n","   Max Stance_Cal_Mid_Z  TimeMax Stance_Cal_Mid_Z  Min Swing_Cal_Mid_Z  \\\n","0             14.862818                 61.403507            10.427507   \n","1             18.627197                 59.911900            13.036373   \n","2              2.766838                 57.142849            -4.752366   \n","3             10.008702                 56.565655             4.635811   \n","4             12.949678                 58.823544             9.222109   \n","\n","   TimeMin Swing_Cal_Mid_Z  Max Swing_Cal_Mid_Z  TimeMax Swing_Cal_Mid_Z  \n","0                83.333328            14.862818                61.403507  \n","1                74.425705            19.120770                79.054405  \n","2               100.000000             3.910995                59.183662  \n","3                88.888885            11.216873                59.090904  \n","4                94.629166            12.848988                58.823544  \n","\n","[5 rows x 48 columns]"],"text/html":["\n","  <div id=\"df-677bab77-1092-4bea-9440-9986b9b72d33\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Min Stance_Cal_Met_X</th>\n","      <th>TimeMin Stance_Cal_Met_X</th>\n","      <th>Max Stance_Cal_Met_X</th>\n","      <th>TimeMax Stance_Cal_Met_X</th>\n","      <th>Min Swing_Cal_Met_X</th>\n","      <th>TimeMin Swing_Cal_Met_X</th>\n","      <th>Max Swing_Cal_Met_X</th>\n","      <th>TimeMax Swing_Cal_Met_X</th>\n","      <th>Min Stance_Cal_Met_Y</th>\n","      <th>TimeMin Stance_Cal_Met_Y</th>\n","      <th>...</th>\n","      <th>Max Swing_Cal_Mid_Y</th>\n","      <th>TimeMax Swing_Cal_Mid_Y</th>\n","      <th>Min Stance_Cal_Mid_Z</th>\n","      <th>TimeMin Stance_Cal_Mid_Z</th>\n","      <th>Max Stance_Cal_Mid_Z</th>\n","      <th>TimeMax Stance_Cal_Mid_Z</th>\n","      <th>Min Swing_Cal_Mid_Z</th>\n","      <th>TimeMin Swing_Cal_Mid_Z</th>\n","      <th>Max Swing_Cal_Mid_Z</th>\n","      <th>TimeMax Swing_Cal_Mid_Z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-54.026958</td>\n","      <td>61.403507</td>\n","      <td>-35.202721</td>\n","      <td>49.999992</td>\n","      <td>-54.026958</td>\n","      <td>61.403507</td>\n","      <td>-44.811600</td>\n","      <td>83.333328</td>\n","      <td>2.690046</td>\n","      <td>59.649124</td>\n","      <td>...</td>\n","      <td>15.548207</td>\n","      <td>61.403507</td>\n","      <td>9.231457</td>\n","      <td>27.192974</td>\n","      <td>14.862818</td>\n","      <td>61.403507</td>\n","      <td>10.427507</td>\n","      <td>83.333328</td>\n","      <td>14.862818</td>\n","      <td>61.403507</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-56.390499</td>\n","      <td>61.674011</td>\n","      <td>-38.140205</td>\n","      <td>50.220276</td>\n","      <td>-56.392658</td>\n","      <td>61.674011</td>\n","      <td>-46.994694</td>\n","      <td>85.435318</td>\n","      <td>-2.237977</td>\n","      <td>59.911900</td>\n","      <td>...</td>\n","      <td>14.974817</td>\n","      <td>82.173958</td>\n","      <td>14.356872</td>\n","      <td>2.643190</td>\n","      <td>18.627197</td>\n","      <td>59.911900</td>\n","      <td>13.036373</td>\n","      <td>74.425705</td>\n","      <td>19.120770</td>\n","      <td>79.054405</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-57.696159</td>\n","      <td>57.142849</td>\n","      <td>-44.452549</td>\n","      <td>44.897938</td>\n","      <td>-61.410961</td>\n","      <td>60.204071</td>\n","      <td>-53.242382</td>\n","      <td>82.653053</td>\n","      <td>8.506367</td>\n","      <td>57.142849</td>\n","      <td>...</td>\n","      <td>30.587400</td>\n","      <td>59.183662</td>\n","      <td>-8.341793</td>\n","      <td>38.775494</td>\n","      <td>2.766838</td>\n","      <td>57.142849</td>\n","      <td>-4.752366</td>\n","      <td>100.000000</td>\n","      <td>3.910995</td>\n","      <td>59.183662</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-47.870407</td>\n","      <td>56.565655</td>\n","      <td>-29.118155</td>\n","      <td>41.414127</td>\n","      <td>-51.179707</td>\n","      <td>59.595955</td>\n","      <td>-40.516735</td>\n","      <td>83.838394</td>\n","      <td>7.041844</td>\n","      <td>56.565655</td>\n","      <td>...</td>\n","      <td>26.770086</td>\n","      <td>56.565655</td>\n","      <td>-0.155559</td>\n","      <td>40.404026</td>\n","      <td>10.008702</td>\n","      <td>56.565655</td>\n","      <td>4.635811</td>\n","      <td>88.888885</td>\n","      <td>11.216873</td>\n","      <td>59.090904</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-40.664665</td>\n","      <td>58.823544</td>\n","      <td>-25.658703</td>\n","      <td>46.150841</td>\n","      <td>-43.398392</td>\n","      <td>61.538799</td>\n","      <td>-33.849476</td>\n","      <td>82.793419</td>\n","      <td>3.865908</td>\n","      <td>58.823544</td>\n","      <td>...</td>\n","      <td>10.832327</td>\n","      <td>92.739426</td>\n","      <td>8.962367</td>\n","      <td>42.544018</td>\n","      <td>12.949678</td>\n","      <td>58.823544</td>\n","      <td>9.222109</td>\n","      <td>94.629166</td>\n","      <td>12.848988</td>\n","      <td>58.823544</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 48 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-677bab77-1092-4bea-9440-9986b9b72d33')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-677bab77-1092-4bea-9440-9986b9b72d33 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-677bab77-1092-4bea-9440-9986b9b72d33');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["segments[\"Cal_Met_Cal_Mid\"].columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e6WKpNlJd9ix","executionInfo":{"status":"ok","timestamp":1663862450318,"user_tz":180,"elapsed":3,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"41dfc62c-7044-4f53-9df8-d8985a270e92"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Min Stance_Cal_Met_X', 'TimeMin Stance_Cal_Met_X',\n","       'Max Stance_Cal_Met_X', 'TimeMax Stance_Cal_Met_X',\n","       'Min Swing_Cal_Met_X', 'TimeMin Swing_Cal_Met_X', 'Max Swing_Cal_Met_X',\n","       'TimeMax Swing_Cal_Met_X', 'Min Stance_Cal_Met_Y',\n","       'TimeMin Stance_Cal_Met_Y', 'Max Stance_Cal_Met_Y',\n","       'TimeMax Stance_Cal_Met_Y', 'Min Swing_Cal_Met_Y',\n","       'TimeMin Swing_Cal_Met_Y', 'Max Swing_Cal_Met_Y',\n","       'TimeMax Swing_Cal_Met_Y', 'Min Stance_Cal_Met_Z',\n","       'TimeMin Stance_Cal_Met_Z', 'Max Stance_Cal_Met_Z',\n","       'TimeMax Stance_Cal_Met_Z', 'Min Swing_Cal_Met_Z',\n","       'TimeMin Swing_Cal_Met_Z', 'Max Swing_Cal_Met_Z',\n","       'TimeMax Swing_Cal_Met_Z', 'Min Stance_Cal_Mid_X',\n","       'TimeMin Stance_Cal_Mid_X', 'Max Stance_Cal_Mid_X',\n","       'TimeMax Stance_Cal_Mid_X', 'Min Swing_Cal_Mid_X',\n","       'TimeMin Swing_Cal_Mid_X', 'Max Swing_Cal_Mid_X',\n","       'TimeMax Swing_Cal_Mid_X', 'Min Stance_Cal_Mid_Y',\n","       'TimeMin Stance_Cal_Mid_Y', 'Max Stance_Cal_Mid_Y',\n","       'TimeMax Stance_Cal_Mid_Y', 'Min Swing_Cal_Mid_Y',\n","       'TimeMin Swing_Cal_Mid_Y', 'Max Swing_Cal_Mid_Y',\n","       'TimeMax Swing_Cal_Mid_Y', 'Min Stance_Cal_Mid_Z',\n","       'TimeMin Stance_Cal_Mid_Z', 'Max Stance_Cal_Mid_Z',\n","       'TimeMax Stance_Cal_Mid_Z', 'Min Swing_Cal_Mid_Z',\n","       'TimeMin Swing_Cal_Mid_Z', 'Max Swing_Cal_Mid_Z',\n","       'TimeMax Swing_Cal_Mid_Z'],\n","      dtype='object')"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["# Defining **Cross Validation** method to be used"],"metadata":{"id":"biPEsyGaJcCm"}},{"cell_type":"code","metadata":{"id":"bIc1szr7JT6v","executionInfo":{"status":"ok","timestamp":1663862450318,"user_tz":180,"elapsed":1,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"source":["# Define Leave-One-Out CV\n","from sklearn.model_selection import LeaveOneOut\n","loocv = LeaveOneOut()\n","\n","# # Define Repeated Stratified k-fold CV\n","# from sklearn.model_selection import cross_validate, RepeatedStratifiedKFold\n","# rskf_cv = RepeatedStratifiedKFold(n_splits=8, n_repeats=5, random_state=36851234)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["# Defning the **Classifer** to be used"],"metadata":{"id":"nloOMmfEJmU9"}},{"cell_type":"code","metadata":{"id":"j-3zxXyQJXvp","executionInfo":{"status":"ok","timestamp":1663864868887,"user_tz":180,"elapsed":4,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"source":["# Define the Classifier to be used for Sequential Feature Selection (SFS)\n","\n","# # Apply Linear LDA\n","# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","# lda = LinearDiscriminantAnalysis(solver='svd', n_components=None)\n","\n","# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n","# Define SVM classifier with RBF kernel\n","from sklearn.svm import SVC\n","svm = SVC(kernel='linear', C=90, verbose=False)"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["# Defining the **Feature Selection** algorithm to be used"],"metadata":{"id":"88qrPopzJxXR"}},{"cell_type":"code","source":["!pip install mlxtend --upgrade"],"metadata":{"id":"xlmQgooyazij","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663864874627,"user_tz":180,"elapsed":5744,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"429779d3-a3ec-442e-ed4d-e49f6d5632a8"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.21.0)\n","Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.0)\n","Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.3.5)\n","Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.21.6)\n","Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.0.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (57.4.0)\n","Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.7.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.0.0->mlxtend) (4.1.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->mlxtend) (2022.2.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.0->mlxtend) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.2->mlxtend) (3.1.0)\n"]}]},{"cell_type":"code","metadata":{"id":"DHhmowQXJakc","executionInfo":{"status":"ok","timestamp":1663864874627,"user_tz":180,"elapsed":7,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"source":["# Define the Sequential Feature Selection class\n","# https://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/\n","\n","# Below is the code for applying Forward Feature Selection\n","from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n","sfs = SFS(estimator=svm, \n","            k_features=(1,15),\n","            forward=True, floating=False,\n","            verbose=2,\n","            scoring=('accuracy'),\n","            cv=loocv,\n","            n_jobs=-1)"],"execution_count":45,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8LBBkwtMS7DT"},"source":["# **Hyper-Parameter Optimization** for Non-Linear SVC (RBF)"]},{"cell_type":"code","metadata":{"id":"-SlsUKmGS5sf","executionInfo":{"status":"ok","timestamp":1663864874627,"user_tz":180,"elapsed":6,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"source":["# Define the Classifier and Parameter Grid to be used for GridSearch and final Evaluation\n","# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n","from sklearn.svm import SVC\n","svm_classifier = SVC()\n","\n","param_grid = [\n","              {'C': [0.01, 0.1, 0, 0.5, 1, 2, 3, 5, 8, 20, 50, 90], \n","               'gamma': ['scale', 'auto', 0.01, 0.03, 0.04, 0.043, 0.045, 0.048, 0.05, 0.053, 0.055, 0.058, 0.06, 0.08, 0.0001, 0.001, 0.1, 1, 10], \n","               'tol':[1e-2, 1e-3, 1e-4, 1e-5], \n","               'kernel': ['linear']}, #rbfSVM\n","]"],"execution_count":46,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HKXGSHqiSnrn"},"source":[":### Change the `estimator` in GridSearch to the estimator you are using."]},{"cell_type":"code","metadata":{"id":"oyCV260fSdpG","executionInfo":{"status":"ok","timestamp":1663864874627,"user_tz":180,"elapsed":6,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"source":["# Define Grid Search class\n","from sklearn.model_selection import GridSearchCV\n","gridSearch = GridSearchCV(estimator=svm_classifier, \n","                          param_grid=param_grid, \n","                          scoring='accuracy',\n","                          n_jobs=-1,\n","                          cv=loocv, # uses Leave One Out CV\n","                          refit=True, verbose=1)"],"execution_count":47,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C_B0Iy5djqi1"},"source":["# Main Driver Code: **Non Linear SVM (RBF)**"]},{"cell_type":"code","metadata":{"id":"uqOUtRfMT4BR","executionInfo":{"status":"ok","timestamp":1663864874628,"user_tz":180,"elapsed":7,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"source":["# Type the name of the Algorithm that you are using\n","# This will be used while Writing the Scores in .txt file\n","# LDA, LinearSVM, SVM (RBF), SVM (polynomial), LogisticRegression, RandomForest\n","algorith_you_are_using = 'linear' "],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"HIlZTMMariR_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2188c4a4-e1f2-4793-84c4-9a186093bcbf","executionInfo":{"status":"ok","timestamp":1663863248156,"user_tz":180,"elapsed":776967,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"source":["'''svm = SVC(kernel='linear', verbose=False, C=1)'''\n","from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n","from utils import *\n","\n","for (key, value) in segments.items():\n","  print(\"Running: \", key)\n","\n","  X = value.values\n","  X = sc.fit_transform(X) # Apply Standard Scaler\n","  print(\"X.shape = \", X.shape)\n","\n","  # Apply Sequetial Forward Feature Selection (SFS)\n","  sfs.k_features = (1, X.shape[1])\n","  sfs.fit(X, y)\n","  print(\"\\nsfs.k_score_ = \", sfs.k_score_)\n","  print(\"sfs.k_feature_idx_ = \", sfs.k_feature_idx_)\n","  \n","  # Apply Grid Search on the Most Significant Parameters\n","  X = sfs.transform(X)\n","  print(\"[After SFS] X.shape = \", X.shape)\n","  search_results = gridSearch.fit(X, y)\n","  \n","  # Get the Best Classfier (Best Parameters) after Grid Search\n","  best_classifier = search_results.best_estimator_\n","  print(\"best_classifier = \", best_classifier)\n","  \n","  # Apply LOOCV to get classification scores\n","  y_true_list, y_pred_list = [], []\n","  for train_idx, test_idx in loocv.split(X, y):\n","      x_train, y_train = X[train_idx], y[train_idx]\n","      x_test, y_test = X[test_idx], y[test_idx]\n","      \n","      best_classifier.fit(x_train, y_train)\n","      \n","      y_pred = best_classifier.predict(x_test)\n","\n","      y_true_list.append(y_test[:])\n","      y_pred_list.append(y_pred[:])\n","  print(\"\\n##############################################################\\n\")\n","\n","  print(\"{}, {}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(algorith_you_are_using, \n","                                                                                          key, \n","                                                                                          accuracy_score(y_true_list, y_pred_list),\n","                                                                                          get_specificity(y_true_list, y_pred_list),\n","                                                                                          get_sensitivity(y_true_list, y_pred_list),\n","                                                                                          get_NPV(y_true_list, y_pred_list),\n","                                                                                          get_PPV(y_true_list, y_pred_list),\n","                                                                                          get_PLR(y_true_list, y_pred_list),\n","                                                                                          f1_score(y_true_list, y_pred_list, labels=[0, 1]),\n","                                                                                          get_MCC(y_true_list, y_pred_list)                                                                                               \n","                                                                                          ))\n","\n","  print(\"\\n##############################################################\")\n"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Running:  Cal_Met_Cal_Mid\n","X.shape =  (72, 48)\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    7.8s\n","[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    9.6s finished\n","\n","[2022-09-22 16:01:21] Features: 1/48 -- score: 0.6805555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    6.6s\n","[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:    9.0s finished\n","\n","[2022-09-22 16:01:30] Features: 2/48 -- score: 0.75[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.9s\n","[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:   13.2s finished\n","\n","[2022-09-22 16:01:43] Features: 3/48 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    5.4s\n","[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    6.1s finished\n","\n","[2022-09-22 16:01:49] Features: 4/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:    3.9s finished\n","\n","[2022-09-22 16:01:53] Features: 5/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:    3.8s finished\n","\n","[2022-09-22 16:01:57] Features: 6/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:    4.0s finished\n","\n","[2022-09-22 16:02:01] Features: 7/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  38 out of  41 | elapsed:    3.7s remaining:    0.3s\n","[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:    3.9s finished\n","\n","[2022-09-22 16:02:05] Features: 8/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    3.8s\n","[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    4.2s finished\n","\n","[2022-09-22 16:02:09] Features: 9/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:    3.9s finished\n","\n","[2022-09-22 16:02:13] Features: 10/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:    3.9s finished\n","\n","[2022-09-22 16:02:17] Features: 11/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:    4.2s finished\n","\n","[2022-09-22 16:02:21] Features: 12/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    4.0s finished\n","\n","[2022-09-22 16:02:25] Features: 13/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    4.0s finished\n","\n","[2022-09-22 16:02:29] Features: 14/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:    4.2s finished\n","\n","[2022-09-22 16:02:33] Features: 15/48 -- score: 0.9166666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    4.3s finished\n","\n","[2022-09-22 16:02:37] Features: 16/48 -- score: 0.9166666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    4.4s finished\n","\n","[2022-09-22 16:02:42] Features: 17/48 -- score: 0.9166666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:    3.9s finished\n","\n","[2022-09-22 16:02:46] Features: 18/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    3.9s finished\n","\n","[2022-09-22 16:02:50] Features: 19/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:    3.7s finished\n","\n","[2022-09-22 16:02:53] Features: 20/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:    3.7s finished\n","\n","[2022-09-22 16:02:57] Features: 21/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    3.5s finished\n","\n","[2022-09-22 16:03:01] Features: 22/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:    3.3s finished\n","\n","[2022-09-22 16:03:04] Features: 23/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    3.8s finished\n","\n","[2022-09-22 16:03:08] Features: 24/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    4.0s finished\n","\n","[2022-09-22 16:03:12] Features: 25/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    2.9s finished\n","\n","[2022-09-22 16:03:15] Features: 26/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    2.8s finished\n","\n","[2022-09-22 16:03:17] Features: 27/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    2.7s finished\n","\n","[2022-09-22 16:03:20] Features: 28/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    2.8s finished\n","\n","[2022-09-22 16:03:23] Features: 29/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    2.7s finished\n","\n","[2022-09-22 16:03:26] Features: 30/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    2.6s finished\n","\n","[2022-09-22 16:03:28] Features: 31/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    2.3s finished\n","\n","[2022-09-22 16:03:31] Features: 32/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    2.1s finished\n","\n","[2022-09-22 16:03:33] Features: 33/48 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.1s finished\n","\n","[2022-09-22 16:03:35] Features: 34/48 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    1.9s finished\n","\n","[2022-09-22 16:03:37] Features: 35/48 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    1.6s finished\n","\n","[2022-09-22 16:03:38] Features: 36/48 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.5s finished\n","\n","[2022-09-22 16:03:40] Features: 37/48 -- score: 0.7916666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    1.4s finished\n","\n","[2022-09-22 16:03:41] Features: 38/48 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.2s finished\n","\n","[2022-09-22 16:03:42] Features: 39/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    1.2s finished\n","\n","[2022-09-22 16:03:44] Features: 40/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    1.0s finished\n","\n","[2022-09-22 16:03:45] Features: 41/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.9s finished\n","\n","[2022-09-22 16:03:46] Features: 42/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s finished\n","\n","[2022-09-22 16:03:46] Features: 43/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n","\n","[2022-09-22 16:03:47] Features: 44/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.5s remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.5s finished\n","\n","[2022-09-22 16:03:48] Features: 45/48 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.4s finished\n","\n","[2022-09-22 16:03:48] Features: 46/48 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s finished\n","\n","[2022-09-22 16:03:48] Features: 47/48 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.1s finished\n","\n","[2022-09-22 16:03:48] Features: 48/48 -- score: 0.8055555555555556"]},{"output_type":"stream","name":"stdout","text":["\n","sfs.k_score_ =  0.9166666666666666\n","sfs.k_feature_idx_ =  (0, 2, 6, 7, 10, 15, 25, 26, 27, 29, 31, 32, 34, 35, 37)\n","[After SFS] X.shape =  (72, 15)\n","Fitting 72 folds for each of 912 candidates, totalling 65664 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","5472 fits failed out of a total of 65664.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","5472 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 255, in fit\n","    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 333, in _dense_fit\n","    random_seed=random_seed,\n","  File \"sklearn/svm/_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n","ValueError: C <= 0\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875     ]\n","  category=UserWarning,\n"]},{"output_type":"stream","name":"stdout","text":["best_classifier =  SVC(C=1, kernel='linear', tol=0.01)\n","\n","##############################################################\n","\n","linear, Cal_Met_Cal_Mid, 0.917, 0.917, 0.917, 0.917, 0.917, 11.000, 0.917, 0.833\n","\n","##############################################################\n"]}]},{"cell_type":"code","source":["'''svm = SVC(kernel='linear', C=30, verbose=False)'''\n","from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n","from utils import *\n","\n","for (key, value) in segments.items():\n","  print(\"Running: \", key)\n","\n","  X = value.values\n","  X = sc.fit_transform(X) # Apply Standard Scaler\n","  print(\"X.shape = \", X.shape)\n","\n","  # Apply Sequetial Forward Feature Selection (SFS)\n","  sfs.k_features = (1, X.shape[1])\n","  sfs.fit(X, y)\n","  print(\"\\nsfs.k_score_ = \", sfs.k_score_)\n","  print(\"sfs.k_feature_idx_ = \", sfs.k_feature_idx_)\n","  \n","  # Apply Grid Search on the Most Significant Parameters\n","  X = sfs.transform(X)\n","  print(\"[After SFS] X.shape = \", X.shape)\n","  search_results = gridSearch.fit(X, y)\n","  \n","  # Get the Best Classfier (Best Parameters) after Grid Search\n","  best_classifier = search_results.best_estimator_\n","  print(\"best_classifier = \", best_classifier)\n","  \n","  # Apply LOOCV to get classification scores\n","  y_true_list, y_pred_list = [], []\n","  for train_idx, test_idx in loocv.split(X, y):\n","      x_train, y_train = X[train_idx], y[train_idx]\n","      x_test, y_test = X[test_idx], y[test_idx]\n","      \n","      best_classifier.fit(x_train, y_train)\n","      \n","      y_pred = best_classifier.predict(x_test)\n","\n","      y_true_list.append(y_test[:])\n","      y_pred_list.append(y_pred[:])\n","  print(\"\\n##############################################################\\n\")\n","\n","  print(\"{}, {}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(algorith_you_are_using, \n","                                                                                          key, \n","                                                                                          accuracy_score(y_true_list, y_pred_list),\n","                                                                                          get_specificity(y_true_list, y_pred_list),\n","                                                                                          get_sensitivity(y_true_list, y_pred_list),\n","                                                                                          get_NPV(y_true_list, y_pred_list),\n","                                                                                          get_PPV(y_true_list, y_pred_list),\n","                                                                                          get_PLR(y_true_list, y_pred_list),\n","                                                                                          f1_score(y_true_list, y_pred_list, labels=[0, 1]),\n","                                                                                          get_MCC(y_true_list, y_pred_list)                                                                                               \n","                                                                                          ))\n","\n","  print(\"\\n##############################################################\")\n"],"metadata":{"id":"_7XAcpz6hof5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663863792542,"user_tz":180,"elapsed":539617,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"eb7e57be-247f-4030-e7cf-542dd31d5739"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Running:  Cal_Met_Cal_Mid\n","X.shape =  (72, 48)\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    5.4s finished\n","\n","[2022-09-22 16:14:17] Features: 1/48 -- score: 0.6666666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    8.2s\n","[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:   10.4s finished\n","\n","[2022-09-22 16:14:28] Features: 2/48 -- score: 0.75[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.3s\n","[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:   12.6s finished\n","\n","[2022-09-22 16:14:40] Features: 3/48 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    8.7s\n","[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   10.0s finished\n","\n","[2022-09-22 16:14:50] Features: 4/48 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    9.1s\n","[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:   10.7s finished\n","\n","[2022-09-22 16:15:01] Features: 5/48 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   14.2s\n","[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:   16.8s finished\n","\n","[2022-09-22 16:15:18] Features: 6/48 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   17.4s\n","[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:   19.6s finished\n","\n","[2022-09-22 16:15:37] Features: 7/48 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   13.5s\n","[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:   15.8s finished\n","\n","[2022-09-22 16:15:53] Features: 8/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   13.4s\n","[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   14.8s finished\n","\n","[2022-09-22 16:16:08] Features: 9/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:   18.8s finished\n","\n","[2022-09-22 16:16:27] Features: 10/48 -- score: 0.9166666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:   11.3s finished\n","\n","[2022-09-22 16:16:38] Features: 11/48 -- score: 0.9166666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:   13.5s finished\n","\n","[2022-09-22 16:16:52] Features: 12/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   15.5s finished\n","\n","[2022-09-22 16:17:07] Features: 13/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:   19.2s finished\n","\n","[2022-09-22 16:17:26] Features: 14/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:    9.4s finished\n","\n","[2022-09-22 16:17:36] Features: 15/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    9.8s finished\n","\n","[2022-09-22 16:17:46] Features: 16/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    9.1s finished\n","\n","[2022-09-22 16:17:55] Features: 17/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:   10.2s finished\n","\n","[2022-09-22 16:18:05] Features: 18/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    7.7s finished\n","\n","[2022-09-22 16:18:13] Features: 19/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:    7.9s finished\n","\n","[2022-09-22 16:18:20] Features: 20/48 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:    9.0s finished\n","\n","[2022-09-22 16:18:30] Features: 21/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    9.5s finished\n","\n","[2022-09-22 16:18:39] Features: 22/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:    9.2s finished\n","\n","[2022-09-22 16:18:48] Features: 23/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    8.7s finished\n","\n","[2022-09-22 16:18:57] Features: 24/48 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    7.9s finished\n","\n","[2022-09-22 16:19:05] Features: 25/48 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    7.3s finished\n","\n","[2022-09-22 16:19:12] Features: 26/48 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    6.5s finished\n","\n","[2022-09-22 16:19:19] Features: 27/48 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    5.8s finished\n","\n","[2022-09-22 16:19:25] Features: 28/48 -- score: 0.7916666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    5.6s finished\n","\n","[2022-09-22 16:19:30] Features: 29/48 -- score: 0.7916666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    2.6s finished\n","\n","[2022-09-22 16:19:33] Features: 30/48 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    2.7s finished\n","\n","[2022-09-22 16:19:35] Features: 31/48 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    2.4s finished\n","\n","[2022-09-22 16:19:38] Features: 32/48 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    2.4s finished\n","\n","[2022-09-22 16:19:40] Features: 33/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.1s finished\n","\n","[2022-09-22 16:19:42] Features: 34/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    2.6s finished\n","\n","[2022-09-22 16:19:45] Features: 35/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    2.0s finished\n","\n","[2022-09-22 16:19:47] Features: 36/48 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.8s finished\n","\n","[2022-09-22 16:19:49] Features: 37/48 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    1.6s finished\n","\n","[2022-09-22 16:19:50] Features: 38/48 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.8s finished\n","\n","[2022-09-22 16:19:52] Features: 39/48 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    2.8s finished\n","\n","[2022-09-22 16:19:55] Features: 40/48 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    1.7s finished\n","\n","[2022-09-22 16:19:57] Features: 41/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    1.0s finished\n","\n","[2022-09-22 16:19:58] Features: 42/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s finished\n","\n","[2022-09-22 16:19:58] Features: 43/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n","\n","[2022-09-22 16:19:59] Features: 44/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.6s remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.6s finished\n","\n","[2022-09-22 16:20:00] Features: 45/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.5s finished\n","\n","[2022-09-22 16:20:00] Features: 46/48 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s finished\n","\n","[2022-09-22 16:20:01] Features: 47/48 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.1s finished\n","\n","[2022-09-22 16:20:01] Features: 48/48 -- score: 0.8055555555555556"]},{"output_type":"stream","name":"stdout","text":["\n","sfs.k_score_ =  0.9166666666666666\n","sfs.k_feature_idx_ =  (5, 6, 7, 24, 29, 31, 35, 38, 40, 45)\n","[After SFS] X.shape =  (72, 10)\n","Fitting 72 folds for each of 912 candidates, totalling 65664 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","5472 fits failed out of a total of 65664.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","5472 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 255, in fit\n","    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 333, in _dense_fit\n","    random_seed=random_seed,\n","  File \"sklearn/svm/_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n","ValueError: C <= 0\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667]\n","  category=UserWarning,\n"]},{"output_type":"stream","name":"stdout","text":["best_classifier =  SVC(C=8, kernel='linear', tol=0.01)\n","\n","##############################################################\n","\n","linear, Cal_Met_Cal_Mid, 0.917, 0.972, 0.861, 0.875, 0.969, 31.000, 0.912, 0.839\n","\n","##############################################################\n"]}]},{"cell_type":"code","source":["'''svm = SVC(kernel='linear', C=60, verbose=False)'''\n","from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n","from utils import *\n","\n","for (key, value) in segments.items():\n","  print(\"Running: \", key)\n","\n","  X = value.values\n","  X = sc.fit_transform(X) # Apply Standard Scaler\n","  print(\"X.shape = \", X.shape)\n","\n","  # Apply Sequetial Forward Feature Selection (SFS)\n","  sfs.k_features = (1, X.shape[1])\n","  sfs.fit(X, y)\n","  print(\"\\nsfs.k_score_ = \", sfs.k_score_)\n","  print(\"sfs.k_feature_idx_ = \", sfs.k_feature_idx_)\n","  \n","  # Apply Grid Search on the Most Significant Parameters\n","  X = sfs.transform(X)\n","  print(\"[After SFS] X.shape = \", X.shape)\n","  search_results = gridSearch.fit(X, y)\n","  \n","  # Get the Best Classfier (Best Parameters) after Grid Search\n","  best_classifier = search_results.best_estimator_\n","  print(\"best_classifier = \", best_classifier)\n","  \n","  # Apply LOOCV to get classification scores\n","  y_true_list, y_pred_list = [], []\n","  for train_idx, test_idx in loocv.split(X, y):\n","      x_train, y_train = X[train_idx], y[train_idx]\n","      x_test, y_test = X[test_idx], y[test_idx]\n","      \n","      best_classifier.fit(x_train, y_train)\n","      \n","      y_pred = best_classifier.predict(x_test)\n","\n","      y_true_list.append(y_test[:])\n","      y_pred_list.append(y_pred[:])\n","  print(\"\\n##############################################################\\n\")\n","\n","  print(\"{}, {}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(algorith_you_are_using, \n","                                                                                          key, \n","                                                                                          accuracy_score(y_true_list, y_pred_list),\n","                                                                                          get_specificity(y_true_list, y_pred_list),\n","                                                                                          get_sensitivity(y_true_list, y_pred_list),\n","                                                                                          get_NPV(y_true_list, y_pred_list),\n","                                                                                          get_PPV(y_true_list, y_pred_list),\n","                                                                                          get_PLR(y_true_list, y_pred_list),\n","                                                                                          f1_score(y_true_list, y_pred_list, labels=[0, 1]),\n","                                                                                          get_MCC(y_true_list, y_pred_list)                                                                                               \n","                                                                                          ))\n","\n","  print(\"\\n##############################################################\")\n"],"metadata":{"id":"QynMgXGkg_TN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663864868575,"user_tz":180,"elapsed":1069799,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"aa422e1c-3c9a-4789-f8e7-5659a380513f"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Running:  Cal_Met_Cal_Mid\n","X.shape =  (72, 48)\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    5.0s\n","[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    7.0s finished\n","\n","[2022-09-22 16:23:25] Features: 1/48 -- score: 0.6666666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.2s\n","[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:   12.8s finished\n","\n","[2022-09-22 16:23:38] Features: 2/48 -- score: 0.75[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   13.2s\n","[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:   15.6s finished\n","\n","[2022-09-22 16:23:53] Features: 3/48 -- score: 0.7638888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.3s\n","[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   12.2s finished\n","\n","[2022-09-22 16:24:05] Features: 4/48 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   14.5s\n","[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:   16.5s finished\n","\n","[2022-09-22 16:24:22] Features: 5/48 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   18.6s\n","[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:   21.3s finished\n","\n","[2022-09-22 16:24:43] Features: 6/48 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   23.9s\n","[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:   27.8s finished\n","\n","[2022-09-22 16:25:11] Features: 7/48 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   23.8s\n","[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:   25.8s finished\n","\n","[2022-09-22 16:25:37] Features: 8/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   23.5s\n","[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   25.1s finished\n","\n","[2022-09-22 16:26:02] Features: 9/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:   35.0s finished\n","\n","[2022-09-22 16:26:37] Features: 10/48 -- score: 0.9166666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:   18.1s finished\n","\n","[2022-09-22 16:26:55] Features: 11/48 -- score: 0.9166666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:   23.5s finished\n","\n","[2022-09-22 16:27:19] Features: 12/48 -- score: 0.9166666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   23.3s finished\n","\n","[2022-09-22 16:27:42] Features: 13/48 -- score: 0.9166666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:   24.5s finished\n","\n","[2022-09-22 16:28:06] Features: 14/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:   23.5s finished\n","\n","[2022-09-22 16:28:30] Features: 15/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:   32.8s finished\n","\n","[2022-09-22 16:29:03] Features: 16/48 -- score: 0.9166666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:   48.5s finished\n","\n","[2022-09-22 16:29:51] Features: 17/48 -- score: 0.9166666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:   26.9s finished\n","\n","[2022-09-22 16:30:18] Features: 18/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   34.1s finished\n","\n","[2022-09-22 16:30:52] Features: 19/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:   38.7s finished\n","\n","[2022-09-22 16:31:31] Features: 20/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:   43.9s finished\n","\n","[2022-09-22 16:32:15] Features: 21/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   39.6s finished\n","\n","[2022-09-22 16:32:54] Features: 22/48 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:   30.5s finished\n","\n","[2022-09-22 16:33:25] Features: 23/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   34.4s finished\n","\n","[2022-09-22 16:33:59] Features: 24/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   34.4s finished\n","\n","[2022-09-22 16:34:34] Features: 25/48 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:   31.6s finished\n","\n","[2022-09-22 16:35:05] Features: 26/48 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:   33.1s finished\n","\n","[2022-09-22 16:35:38] Features: 27/48 -- score: 0.7916666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:   23.1s finished\n","\n","[2022-09-22 16:36:01] Features: 28/48 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   23.2s finished\n","\n","[2022-09-22 16:36:25] Features: 29/48 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:   20.9s finished\n","\n","[2022-09-22 16:36:46] Features: 30/48 -- score: 0.7638888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:   24.5s finished\n","\n","[2022-09-22 16:37:10] Features: 31/48 -- score: 0.7361111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:   12.0s finished\n","\n","[2022-09-22 16:37:22] Features: 32/48 -- score: 0.7638888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:   14.7s finished\n","\n","[2022-09-22 16:37:37] Features: 33/48 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    3.2s finished\n","\n","[2022-09-22 16:37:40] Features: 34/48 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    2.3s finished\n","\n","[2022-09-22 16:37:42] Features: 35/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    2.2s finished\n","\n","[2022-09-22 16:37:44] Features: 36/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    2.0s finished\n","\n","[2022-09-22 16:37:47] Features: 37/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    2.0s finished\n","\n","[2022-09-22 16:37:48] Features: 38/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.7s finished\n","\n","[2022-09-22 16:37:50] Features: 39/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    1.5s finished\n","\n","[2022-09-22 16:37:52] Features: 40/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    1.3s finished\n","\n","[2022-09-22 16:37:53] Features: 41/48 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    1.1s finished\n","\n","[2022-09-22 16:37:54] Features: 42/48 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.9s finished\n","\n","[2022-09-22 16:37:55] Features: 43/48 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.7s finished\n","\n","[2022-09-22 16:37:56] Features: 44/48 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.6s remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.6s finished\n","\n","[2022-09-22 16:37:56] Features: 45/48 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.5s finished\n","\n","[2022-09-22 16:37:57] Features: 46/48 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s finished\n","\n","[2022-09-22 16:37:57] Features: 47/48 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.1s finished\n","\n","[2022-09-22 16:37:57] Features: 48/48 -- score: 0.8055555555555556"]},{"output_type":"stream","name":"stdout","text":["\n","sfs.k_score_ =  0.9166666666666666\n","sfs.k_feature_idx_ =  (5, 6, 7, 24, 29, 31, 35, 38, 40, 45)\n","[After SFS] X.shape =  (72, 10)\n","Fitting 72 folds for each of 912 candidates, totalling 65664 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","5472 fits failed out of a total of 65664.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","5472 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 255, in fit\n","    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 333, in _dense_fit\n","    random_seed=random_seed,\n","  File \"sklearn/svm/_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n","ValueError: C <= 0\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667]\n","  category=UserWarning,\n"]},{"output_type":"stream","name":"stdout","text":["best_classifier =  SVC(C=8, kernel='linear', tol=0.01)\n","\n","##############################################################\n","\n","linear, Cal_Met_Cal_Mid, 0.917, 0.972, 0.861, 0.875, 0.969, 31.000, 0.912, 0.839\n","\n","##############################################################\n"]}]},{"cell_type":"code","source":["'''svm = SVC(kernel='linear', verbose=False, C=90)'''\n","from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n","from utils import *\n","\n","for (key, value) in segments.items():\n","  print(\"Running: \", key)\n","\n","  X = value.values\n","  X = sc.fit_transform(X) # Apply Standard Scaler\n","  print(\"X.shape = \", X.shape)\n","\n","  # Apply Sequetial Forward Feature Selection (SFS)\n","  sfs.k_features = (1, X.shape[1])\n","  sfs.fit(X, y)\n","  print(\"\\nsfs.k_score_ = \", sfs.k_score_)\n","  print(\"sfs.k_feature_idx_ = \", sfs.k_feature_idx_)\n","  \n","  # Apply Grid Search on the Most Significant Parameters\n","  X = sfs.transform(X)\n","  print(\"[After SFS] X.shape = \", X.shape)\n","  search_results = gridSearch.fit(X, y)\n","  \n","  # Get the Best Classfier (Best Parameters) after Grid Search\n","  best_classifier = search_results.best_estimator_\n","  print(\"best_classifier = \", best_classifier)\n","  \n","  # Apply LOOCV to get classification scores\n","  y_true_list, y_pred_list = [], []\n","  for train_idx, test_idx in loocv.split(X, y):\n","      x_train, y_train = X[train_idx], y[train_idx]\n","      x_test, y_test = X[test_idx], y[test_idx]\n","      \n","      best_classifier.fit(x_train, y_train)\n","      \n","      y_pred = best_classifier.predict(x_test)\n","\n","      y_true_list.append(y_test[:])\n","      y_pred_list.append(y_pred[:])\n","  print(\"\\n##############################################################\\n\")\n","\n","  print(\"{}, {}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(algorith_you_are_using, \n","                                                                                          key, \n","                                                                                          accuracy_score(y_true_list, y_pred_list),\n","                                                                                          get_specificity(y_true_list, y_pred_list),\n","                                                                                          get_sensitivity(y_true_list, y_pred_list),\n","                                                                                          get_NPV(y_true_list, y_pred_list),\n","                                                                                          get_PPV(y_true_list, y_pred_list),\n","                                                                                          get_PLR(y_true_list, y_pred_list),\n","                                                                                          f1_score(y_true_list, y_pred_list, labels=[0, 1]),\n","                                                                                          get_MCC(y_true_list, y_pred_list)                                                                                               \n","                                                                                          ))\n","\n","  print(\"\\n##############################################################\")\n"],"metadata":{"id":"5N9wrGu3EwMe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663866181359,"user_tz":180,"elapsed":1306737,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"4a62d4e7-9156-47e9-8d37-5572458b230d"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Running:  Cal_Met_Cal_Mid\n","X.shape =  (72, 48)\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    6.7s\n","[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    8.7s finished\n","\n","[2022-09-22 16:41:22] Features: 1/48 -- score: 0.6666666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.7s\n","[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:   13.5s finished\n","\n","[2022-09-22 16:41:36] Features: 2/48 -- score: 0.75[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   13.5s\n","[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:   15.3s finished\n","\n","[2022-09-22 16:41:51] Features: 3/48 -- score: 0.7638888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.7s\n","[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   13.2s finished\n","\n","[2022-09-22 16:42:04] Features: 4/48 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   14.7s\n","[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:   17.7s finished\n","\n","[2022-09-22 16:42:22] Features: 5/48 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   17.5s\n","[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:   20.2s finished\n","\n","[2022-09-22 16:42:42] Features: 6/48 -- score: 0.7916666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   22.4s\n","[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:   24.8s finished\n","\n","[2022-09-22 16:43:07] Features: 7/48 -- score: 0.7916666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   21.6s\n","[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:   23.4s finished\n","\n","[2022-09-22 16:43:31] Features: 8/48 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   31.7s\n","[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   33.6s finished\n","\n","[2022-09-22 16:44:04] Features: 9/48 -- score: 0.7916666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:   33.6s finished\n","\n","[2022-09-22 16:44:38] Features: 10/48 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:   31.6s finished\n","\n","[2022-09-22 16:45:09] Features: 11/48 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:   35.3s finished\n","\n","[2022-09-22 16:45:45] Features: 12/48 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   24.1s finished\n","\n","[2022-09-22 16:46:09] Features: 13/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:   33.1s finished\n","\n","[2022-09-22 16:46:42] Features: 14/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:   46.8s finished\n","\n","[2022-09-22 16:47:29] Features: 15/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:   44.2s finished\n","\n","[2022-09-22 16:48:13] Features: 16/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:   52.6s finished\n","\n","[2022-09-22 16:49:06] Features: 17/48 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:   41.1s finished\n","\n","[2022-09-22 16:49:47] Features: 18/48 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   35.3s finished\n","\n","[2022-09-22 16:50:22] Features: 19/48 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:   27.0s finished\n","\n","[2022-09-22 16:50:49] Features: 20/48 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:   29.0s finished\n","\n","[2022-09-22 16:51:18] Features: 21/48 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   23.0s finished\n","\n","[2022-09-22 16:51:41] Features: 22/48 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:   20.0s finished\n","\n","[2022-09-22 16:52:01] Features: 23/48 -- score: 0.7916666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   17.4s finished\n","\n","[2022-09-22 16:52:18] Features: 24/48 -- score: 0.7638888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   16.8s finished\n","\n","[2022-09-22 16:52:35] Features: 25/48 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    5.1s finished\n","\n","[2022-09-22 16:52:40] Features: 26/48 -- score: 0.7916666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    4.8s finished\n","\n","[2022-09-22 16:52:45] Features: 27/48 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    4.8s finished\n","\n","[2022-09-22 16:52:50] Features: 28/48 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    4.6s finished\n","\n","[2022-09-22 16:52:54] Features: 29/48 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    3.3s finished\n","\n","[2022-09-22 16:52:58] Features: 30/48 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    3.0s finished\n","\n","[2022-09-22 16:53:01] Features: 31/48 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    2.6s finished\n","\n","[2022-09-22 16:53:03] Features: 32/48 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    2.5s finished\n","\n","[2022-09-22 16:53:06] Features: 33/48 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    1.9s finished\n","\n","[2022-09-22 16:53:08] Features: 34/48 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    1.7s finished\n","\n","[2022-09-22 16:53:10] Features: 35/48 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    1.7s finished\n","\n","[2022-09-22 16:53:11] Features: 36/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    1.7s finished\n","\n","[2022-09-22 16:53:13] Features: 37/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    1.6s finished\n","\n","[2022-09-22 16:53:15] Features: 38/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.4s finished\n","\n","[2022-09-22 16:53:16] Features: 39/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    1.3s finished\n","\n","[2022-09-22 16:53:17] Features: 40/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    1.2s finished\n","\n","[2022-09-22 16:53:18] Features: 41/48 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    1.1s finished\n","\n","[2022-09-22 16:53:19] Features: 42/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.9s finished\n","\n","[2022-09-22 16:53:20] Features: 43/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n","\n","[2022-09-22 16:53:21] Features: 44/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.6s remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.6s finished\n","\n","[2022-09-22 16:53:22] Features: 45/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.4s finished\n","\n","[2022-09-22 16:53:22] Features: 46/48 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s finished\n","\n","[2022-09-22 16:53:23] Features: 47/48 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.1s finished\n","\n","[2022-09-22 16:53:23] Features: 48/48 -- score: 0.8055555555555556"]},{"output_type":"stream","name":"stdout","text":["\n","sfs.k_score_ =  0.9027777777777778\n","sfs.k_feature_idx_ =  (3, 5, 10, 16, 19, 20, 23, 25, 27, 31, 36, 37, 42, 45)\n","[After SFS] X.shape =  (72, 14)\n","Fitting 72 folds for each of 912 candidates, totalling 65664 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","5472 fits failed out of a total of 65664.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","5472 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 255, in fit\n","    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 333, in _dense_fit\n","    random_seed=random_seed,\n","  File \"sklearn/svm/_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n","ValueError: C <= 0\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n"," 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444\n"," 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444\n"," 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444\n"," 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444\n"," 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444\n"," 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444\n"," 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444\n"," 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444\n"," 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444\n"," 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444\n"," 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444\n"," 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444 0.81944444\n"," 0.81944444 0.81944444 0.81944444 0.81944444 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.88888889 0.875      0.875      0.875      0.88888889 0.875\n"," 0.875      0.875      0.88888889 0.875      0.875      0.875\n"," 0.88888889 0.875      0.875      0.875      0.88888889 0.875\n"," 0.875      0.875      0.88888889 0.875      0.875      0.875\n"," 0.88888889 0.875      0.875      0.875      0.88888889 0.875\n"," 0.875      0.875      0.88888889 0.875      0.875      0.875\n"," 0.88888889 0.875      0.875      0.875      0.88888889 0.875\n"," 0.875      0.875      0.88888889 0.875      0.875      0.875\n"," 0.88888889 0.875      0.875      0.875      0.88888889 0.875\n"," 0.875      0.875      0.88888889 0.875      0.875      0.875\n"," 0.88888889 0.875      0.875      0.875      0.88888889 0.875\n"," 0.875      0.875      0.88888889 0.875      0.875      0.875\n"," 0.88888889 0.875      0.875      0.875      0.90277778 0.88888889\n"," 0.88888889 0.88888889 0.90277778 0.88888889 0.88888889 0.88888889\n"," 0.90277778 0.88888889 0.88888889 0.88888889 0.90277778 0.88888889\n"," 0.88888889 0.88888889 0.90277778 0.88888889 0.88888889 0.88888889\n"," 0.90277778 0.88888889 0.88888889 0.88888889 0.90277778 0.88888889\n"," 0.88888889 0.88888889 0.90277778 0.88888889 0.88888889 0.88888889\n"," 0.90277778 0.88888889 0.88888889 0.88888889 0.90277778 0.88888889\n"," 0.88888889 0.88888889 0.90277778 0.88888889 0.88888889 0.88888889\n"," 0.90277778 0.88888889 0.88888889 0.88888889 0.90277778 0.88888889\n"," 0.88888889 0.88888889 0.90277778 0.88888889 0.88888889 0.88888889\n"," 0.90277778 0.88888889 0.88888889 0.88888889 0.90277778 0.88888889\n"," 0.88888889 0.88888889 0.90277778 0.88888889 0.88888889 0.88888889\n"," 0.90277778 0.88888889 0.88888889 0.88888889 0.90277778 0.88888889\n"," 0.88888889 0.88888889 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778]\n","  category=UserWarning,\n"]},{"output_type":"stream","name":"stdout","text":["best_classifier =  SVC(C=50, kernel='linear', tol=0.01)\n","\n","##############################################################\n","\n","linear, Cal_Met_Cal_Mid, 0.903, 0.889, 0.917, 0.914, 0.892, 8.250, 0.904, 0.806\n","\n","##############################################################\n"]}]},{"cell_type":"markdown","metadata":{"id":"begowljae4wE"},"source":["# **Verification**"]},{"cell_type":"code","source":["# get the names of the feature subset selected using the Feature Selection algorithm.\n","sfs_feature_idx = [5, 6, 7, 24, 29, 31, 35, 38, 40, 45]\n","print(\"Number of Features selected: \", len(sfs_feature_idx))\n","\n","segments[\"Cal_Met_Cal_Mid\"].iloc[:, sfs_feature_idx].head()"],"metadata":{"id":"5zc0runCO1oW","colab":{"base_uri":"https://localhost:8080/","height":285},"executionInfo":{"status":"ok","timestamp":1663866353311,"user_tz":180,"elapsed":275,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"d0fc630f-64e8-4510-ca6c-153e0ea97d31"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Features selected:  10\n"]},{"output_type":"execute_result","data":{"text/plain":["   TimeMin Swing_Cal_Met_X  Max Swing_Cal_Met_X  TimeMax Swing_Cal_Met_X  \\\n","0                61.403507           -44.811600                83.333328   \n","1                61.674011           -46.994694                85.435318   \n","2                60.204071           -53.242382                82.653053   \n","3                59.595955           -40.516735                83.838394   \n","4                61.538799           -33.849476                82.793419   \n","\n","   Min Stance_Cal_Mid_X  TimeMin Swing_Cal_Mid_X  TimeMax Swing_Cal_Mid_X  \\\n","0             16.543676                61.403507                83.333328   \n","1             24.506611                61.674011                87.805359   \n","2             15.469666                59.183662               100.000000   \n","3             16.562412                59.595955                90.909088   \n","4             26.373043                61.081284                88.810745   \n","\n","   TimeMax Stance_Cal_Mid_Y  Max Swing_Cal_Mid_Y  Min Stance_Cal_Mid_Z  \\\n","0                 58.771931            15.548207              9.231457   \n","1                  1.762134            14.974817             14.356872   \n","2                 57.142849            30.587400             -8.341793   \n","3                 55.555553            26.770086             -0.155559   \n","4                  0.000000            10.832327              8.962367   \n","\n","   TimeMin Swing_Cal_Mid_Z  \n","0                83.333328  \n","1                74.425705  \n","2               100.000000  \n","3                88.888885  \n","4                94.629166  "],"text/html":["\n","  <div id=\"df-63f237af-0513-42d9-8349-fbef67fbe5ec\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TimeMin Swing_Cal_Met_X</th>\n","      <th>Max Swing_Cal_Met_X</th>\n","      <th>TimeMax Swing_Cal_Met_X</th>\n","      <th>Min Stance_Cal_Mid_X</th>\n","      <th>TimeMin Swing_Cal_Mid_X</th>\n","      <th>TimeMax Swing_Cal_Mid_X</th>\n","      <th>TimeMax Stance_Cal_Mid_Y</th>\n","      <th>Max Swing_Cal_Mid_Y</th>\n","      <th>Min Stance_Cal_Mid_Z</th>\n","      <th>TimeMin Swing_Cal_Mid_Z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>61.403507</td>\n","      <td>-44.811600</td>\n","      <td>83.333328</td>\n","      <td>16.543676</td>\n","      <td>61.403507</td>\n","      <td>83.333328</td>\n","      <td>58.771931</td>\n","      <td>15.548207</td>\n","      <td>9.231457</td>\n","      <td>83.333328</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>61.674011</td>\n","      <td>-46.994694</td>\n","      <td>85.435318</td>\n","      <td>24.506611</td>\n","      <td>61.674011</td>\n","      <td>87.805359</td>\n","      <td>1.762134</td>\n","      <td>14.974817</td>\n","      <td>14.356872</td>\n","      <td>74.425705</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>60.204071</td>\n","      <td>-53.242382</td>\n","      <td>82.653053</td>\n","      <td>15.469666</td>\n","      <td>59.183662</td>\n","      <td>100.000000</td>\n","      <td>57.142849</td>\n","      <td>30.587400</td>\n","      <td>-8.341793</td>\n","      <td>100.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>59.595955</td>\n","      <td>-40.516735</td>\n","      <td>83.838394</td>\n","      <td>16.562412</td>\n","      <td>59.595955</td>\n","      <td>90.909088</td>\n","      <td>55.555553</td>\n","      <td>26.770086</td>\n","      <td>-0.155559</td>\n","      <td>88.888885</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>61.538799</td>\n","      <td>-33.849476</td>\n","      <td>82.793419</td>\n","      <td>26.373043</td>\n","      <td>61.081284</td>\n","      <td>88.810745</td>\n","      <td>0.000000</td>\n","      <td>10.832327</td>\n","      <td>8.962367</td>\n","      <td>94.629166</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63f237af-0513-42d9-8349-fbef67fbe5ec')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-63f237af-0513-42d9-8349-fbef67fbe5ec button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-63f237af-0513-42d9-8349-fbef67fbe5ec');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"_VfdqPx7nNxR","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"ok","timestamp":1663866353312,"user_tz":180,"elapsed":4,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"4e1a17f5-e525-48f2-8977-914ba05450e0"},"source":["temp = pd.DataFrame(segments[\"Cal_Met_Cal_Mid\"].keys().to_numpy(), columns=[\"FeatureNames\"])\n","\n","features = temp.iloc[sfs_feature_idx]\n","features"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                FeatureNames\n","5    TimeMin Swing_Cal_Met_X\n","6        Max Swing_Cal_Met_X\n","7    TimeMax Swing_Cal_Met_X\n","24      Min Stance_Cal_Mid_X\n","29   TimeMin Swing_Cal_Mid_X\n","31   TimeMax Swing_Cal_Mid_X\n","35  TimeMax Stance_Cal_Mid_Y\n","38       Max Swing_Cal_Mid_Y\n","40      Min Stance_Cal_Mid_Z\n","45   TimeMin Swing_Cal_Mid_Z"],"text/html":["\n","  <div id=\"df-60126de8-6211-4c3a-9cd3-e82d54fbd0b7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>FeatureNames</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>TimeMin Swing_Cal_Met_X</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Max Swing_Cal_Met_X</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>TimeMax Swing_Cal_Met_X</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Min Stance_Cal_Mid_X</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>TimeMin Swing_Cal_Mid_X</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>TimeMax Swing_Cal_Mid_X</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>TimeMax Stance_Cal_Mid_Y</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>Max Swing_Cal_Mid_Y</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>Min Stance_Cal_Mid_Z</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>TimeMin Swing_Cal_Mid_Z</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60126de8-6211-4c3a-9cd3-e82d54fbd0b7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-60126de8-6211-4c3a-9cd3-e82d54fbd0b7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-60126de8-6211-4c3a-9cd3-e82d54fbd0b7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"Qep9E9ape2nl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663866539733,"user_tz":180,"elapsed":185363,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"4c81cf4d-dcb4-47e6-c4c1-0384cc68f7d7"},"source":["from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n","from utils import *\n","\n","for (key, value) in segments.items():\n","  print(\"Running: \", key)\n","\n","  X = value.iloc[:, sfs_feature_idx].values\n","  X = sc.fit_transform(X) # Standard Scaler\n","  print(\"X.shape = \", X.shape)\n","\n","  search_results = gridSearch.fit(X, y)\n","  \n","  # Get the Best Classfier (Best Parameters) after Grid Search\n","  best_classifier = search_results.best_estimator_\n","  print(\"best_classifier = \", best_classifier)\n","  \n","  # Apply LOOCV to get classification scores\n","  y_true_list, y_pred_list = [], []\n","  for train_idx, test_idx in loocv.split(X, y):\n","      x_train, y_train = X[train_idx], y[train_idx]\n","      x_test, y_test = X[test_idx], y[test_idx]\n","      \n","      best_classifier.fit(x_train, y_train)\n","      \n","      y_pred = best_classifier.predict(x_test)\n","\n","      y_true_list.append(y_test[:])\n","      y_pred_list.append(y_pred[:])\n","\n","  print(\"\\n##############################################################\\n\")\n","\n","  print(\"{}, {}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(algorith_you_are_using, \n","                                                                                          key, \n","                                                                                          accuracy_score(y_true_list, y_pred_list),\n","                                                                                          get_specificity(y_true_list, y_pred_list),\n","                                                                                          get_sensitivity(y_true_list, y_pred_list),\n","                                                                                          get_NPV(y_true_list, y_pred_list),\n","                                                                                          get_PPV(y_true_list, y_pred_list),\n","                                                                                          get_PLR(y_true_list, y_pred_list),\n","                                                                                          f1_score(y_true_list, y_pred_list, labels=[0, 1]),\n","                                                                                          get_MCC(y_true_list, y_pred_list)                                                                                               \n","                                                                                          ))\n","\n","  print(\"\\n##############################################################\")"],"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Running:  Cal_Met_Cal_Mid\n","X.shape =  (72, 10)\n","Fitting 72 folds for each of 912 candidates, totalling 65664 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","5472 fits failed out of a total of 65664.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","5472 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 255, in fit\n","    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 333, in _dense_fit\n","    random_seed=random_seed,\n","  File \"sklearn/svm/_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n","ValueError: C <= 0\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667 0.79166667\n"," 0.79166667 0.79166667 0.79166667 0.79166667 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222 0.84722222\n"," 0.84722222 0.84722222        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111 0.86111111\n"," 0.86111111 0.86111111 0.86111111 0.86111111 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667\n"," 0.90277778 0.91666667 0.91666667 0.91666667 0.90277778 0.91666667\n"," 0.91666667 0.91666667 0.90277778 0.91666667 0.91666667 0.91666667]\n","  category=UserWarning,\n"]},{"output_type":"stream","name":"stdout","text":["best_classifier =  SVC(C=8, kernel='linear', tol=0.01)\n","\n","##############################################################\n","\n","linear, Cal_Met_Cal_Mid, 0.917, 0.972, 0.861, 0.875, 0.969, 31.000, 0.912, 0.839\n","\n","##############################################################\n"]}]},{"cell_type":"code","metadata":{"id":"BcdmtDTJe3_a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663866539734,"user_tz":180,"elapsed":18,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"7598fea7-6594-4b5d-b8d1-6063a8c25de7"},"source":["search_results.best_params_"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'C': 8, 'gamma': 'scale', 'kernel': 'linear', 'tol': 0.01}"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"z23sgafFh0Iq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663866539735,"user_tz":180,"elapsed":14,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"e8d70bb7-a6b9-43b8-8650-0526053990a9"},"source":["search_results.best_score_"],"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9166666666666666"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":[],"metadata":{"id":"g-pz33tScx8g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xBRLrdNtcx3Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GHTnaK5Mcxwq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"F9CVK5jGelKL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"a3Fl1NCgelDo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##############################################################################\n","//////////////////////////////////////////////////////////////////////////////\n","##############################################################################"],"metadata":{"id":"BkEYdgfKcxqh"},"execution_count":null,"outputs":[]}]}