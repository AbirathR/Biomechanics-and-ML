{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN+0Mm0Qp0dTNffIP/YN03+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HpvB6Oxcnm59"},"source":["# **Mounting Google Drive**"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive"],"metadata":{"id":"26yaaUCAxgc4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663250446402,"user_tz":180,"elapsed":16995,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"0d03dfa4-0d83-4256-c5ed-fddeb7622388"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n","/gdrive\n"]}]},{"cell_type":"code","source":["import os\n","os.getcwd()"],"metadata":{"id":"gnQjqn3px5l_","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1663250446402,"user_tz":180,"elapsed":5,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"52eb0992-70a9-4dfd-e6a1-196d7ca63675"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/gdrive'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"rd32VN7-onqw"},"source":["#### Move to the Dataset Dircetory in My Drive"]},{"cell_type":"code","source":["os.chdir(\"/gdrive/MyDrive/Autism_code/Young_vs_Old/Kinetics\")\n","!pwd"],"metadata":{"id":"_xOjnotEx65u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663250446577,"user_tz":180,"elapsed":179,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"05dda5dc-99dd-4552-9b35-c103fafb5b3b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/gdrive/MyDrive/Autism_code/Young_vs_Old/Kinetics\n"]}]},{"cell_type":"code","source":["# importing necessary packages\n","import matplotlib.pyplot as plt  # for making plots / graphs\n","import pandas as pd              # for reading the .csv file and related operations\n","import numpy as np               # for working with arrays (multi-dimensional)  \n","\n","# read the dataset\n","df = pd.read_excel(\"./Master_YoungOld_Kinetics_TypSpeed_reduced_vars.xlsx\")\n","\n","# now, the whole dataset csv dataset file is saved into `df` variable.\n","print(\"df.shape = \", df.shape)\n","df.head(3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":271},"id":"q8w-NuGrbwUd","executionInfo":{"status":"ok","timestamp":1663250448015,"user_tz":180,"elapsed":1445,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"4e2360fe-3e0d-449a-d337-ff490dac673e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["df.shape =  (72, 39)\n"]},{"output_type":"execute_result","data":{"text/plain":["  Participant Side Group  ANKLE Moment_X_MAX_ST..35.70.  \\\n","0        P001    L     Y                         1.6513   \n","1        P001    R     Y                         1.5483   \n","2        P002    L     Y                         1.2021   \n","\n","   ANKLE Moment_X_MAX_ST_time..35.70.  ANKLE Power_X_MAX_ST..35.70.  \\\n","0                              50.435                        4.4286   \n","1                              50.000                        4.5833   \n","2                              45.455                        2.9617   \n","\n","   ANKLE Power_X_MAX_ST_time..35.70.  HIP Moment_X_MAX_ST  \\\n","0                             55.652              0.22744   \n","1                             56.140              0.52977   \n","2                             52.525              0.50208   \n","\n","   HIP Moment_X_MAX_ST_time  HIP Moment_X_MAX_SW  ...  KNEE Power_X_MIN_SW  \\\n","0                   0.86957              0.35350  ...              -1.0523   \n","1                   5.26320              0.39082  ...              -1.5960   \n","2                   6.06060              0.42453  ...              -1.1166   \n","\n","   KNEE Power_X_MIN_SW_time  KNEE Power_X_MAX_ST..12.35.  \\\n","0                    93.043                      0.31687   \n","1                    92.982                      0.37378   \n","2                    88.889                      0.60614   \n","\n","   KNEE Power_X_MAX_ST_time..12.35.  KNEE Power_X_MIN_ST..01.25.  \\\n","0                            22.609                     -0.85170   \n","1                            14.035                     -0.61892   \n","2                            16.162                     -0.97828   \n","\n","   KNEE Power_X_MIN_ST_time..01.25.  KNEE Power_X_MIN_ST..35.70.  \\\n","0                            9.5652                      -1.0244   \n","1                            9.6491                      -1.4494   \n","2                            8.0808                      -2.1391   \n","\n","   KNEE Power_X_MIN_ST_time..35.70.  KNEE Power_X_MAX_ST..01.12.  \\\n","0                            57.391                      0.24955   \n","1                            57.018                      0.35562   \n","2                            54.545                      0.23823   \n","\n","   KNEE Power_X_MAX_ST_time..01.12.  \n","0                           0.86957  \n","1                           0.87719  \n","2                           1.01010  \n","\n","[3 rows x 39 columns]"],"text/html":["\n","  <div id=\"df-5e1bda81-5530-48b9-ac07-d40a75d373a1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Participant</th>\n","      <th>Side</th>\n","      <th>Group</th>\n","      <th>ANKLE Moment_X_MAX_ST..35.70.</th>\n","      <th>ANKLE Moment_X_MAX_ST_time..35.70.</th>\n","      <th>ANKLE Power_X_MAX_ST..35.70.</th>\n","      <th>ANKLE Power_X_MAX_ST_time..35.70.</th>\n","      <th>HIP Moment_X_MAX_ST</th>\n","      <th>HIP Moment_X_MAX_ST_time</th>\n","      <th>HIP Moment_X_MAX_SW</th>\n","      <th>...</th>\n","      <th>KNEE Power_X_MIN_SW</th>\n","      <th>KNEE Power_X_MIN_SW_time</th>\n","      <th>KNEE Power_X_MAX_ST..12.35.</th>\n","      <th>KNEE Power_X_MAX_ST_time..12.35.</th>\n","      <th>KNEE Power_X_MIN_ST..01.25.</th>\n","      <th>KNEE Power_X_MIN_ST_time..01.25.</th>\n","      <th>KNEE Power_X_MIN_ST..35.70.</th>\n","      <th>KNEE Power_X_MIN_ST_time..35.70.</th>\n","      <th>KNEE Power_X_MAX_ST..01.12.</th>\n","      <th>KNEE Power_X_MAX_ST_time..01.12.</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>P001</td>\n","      <td>L</td>\n","      <td>Y</td>\n","      <td>1.6513</td>\n","      <td>50.435</td>\n","      <td>4.4286</td>\n","      <td>55.652</td>\n","      <td>0.22744</td>\n","      <td>0.86957</td>\n","      <td>0.35350</td>\n","      <td>...</td>\n","      <td>-1.0523</td>\n","      <td>93.043</td>\n","      <td>0.31687</td>\n","      <td>22.609</td>\n","      <td>-0.85170</td>\n","      <td>9.5652</td>\n","      <td>-1.0244</td>\n","      <td>57.391</td>\n","      <td>0.24955</td>\n","      <td>0.86957</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>P001</td>\n","      <td>R</td>\n","      <td>Y</td>\n","      <td>1.5483</td>\n","      <td>50.000</td>\n","      <td>4.5833</td>\n","      <td>56.140</td>\n","      <td>0.52977</td>\n","      <td>5.26320</td>\n","      <td>0.39082</td>\n","      <td>...</td>\n","      <td>-1.5960</td>\n","      <td>92.982</td>\n","      <td>0.37378</td>\n","      <td>14.035</td>\n","      <td>-0.61892</td>\n","      <td>9.6491</td>\n","      <td>-1.4494</td>\n","      <td>57.018</td>\n","      <td>0.35562</td>\n","      <td>0.87719</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>P002</td>\n","      <td>L</td>\n","      <td>Y</td>\n","      <td>1.2021</td>\n","      <td>45.455</td>\n","      <td>2.9617</td>\n","      <td>52.525</td>\n","      <td>0.50208</td>\n","      <td>6.06060</td>\n","      <td>0.42453</td>\n","      <td>...</td>\n","      <td>-1.1166</td>\n","      <td>88.889</td>\n","      <td>0.60614</td>\n","      <td>16.162</td>\n","      <td>-0.97828</td>\n","      <td>8.0808</td>\n","      <td>-2.1391</td>\n","      <td>54.545</td>\n","      <td>0.23823</td>\n","      <td>1.01010</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows Ã— 39 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e1bda81-5530-48b9-ac07-d40a75d373a1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5e1bda81-5530-48b9-ac07-d40a75d373a1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5e1bda81-5530-48b9-ac07-d40a75d373a1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# print the columns of the data frame\n","df.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mhJCBiRQbwQV","executionInfo":{"status":"ok","timestamp":1663250448015,"user_tz":180,"elapsed":12,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"34206675-642b-4ac3-fe2d-cb1701251467"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Participant', 'Side', 'Group', 'ANKLE Moment_X_MAX_ST..35.70.',\n","       'ANKLE Moment_X_MAX_ST_time..35.70.', 'ANKLE Power_X_MAX_ST..35.70.',\n","       'ANKLE Power_X_MAX_ST_time..35.70.', 'HIP Moment_X_MAX_ST',\n","       'HIP Moment_X_MAX_ST_time', 'HIP Moment_X_MAX_SW',\n","       'HIP Moment_X_MAX_SW_time', 'HIP Moment_X_MIN_ST..35.70.',\n","       'HIP Moment_X_MIN_ST_time..35.70.', 'HIP Moment_Y_MAX_ST..12.35.',\n","       'HIP Moment_Y_MAX_ST_time..12.35.', 'HIP Moment_Y_MAX_ST..35.70.',\n","       'HIP Moment_Y_MAX_ST_time..35.70.', 'HIP Power_X_MAX_ST..12.35.',\n","       'HIP Power_X_MAX_ST_time..12.35.', 'HIP Power_X_MAX_ST..35.70.',\n","       'HIP Power_X_MAX_ST_time..35.70.', 'HIP Power_X_MIN_ST..35.70.',\n","       'HIP Power_X_MIN_ST_time..35.70.', 'KNEE Moment_X_MIN_ST',\n","       'KNEE Moment_X_MIN_ST_time', 'KNEE Moment_X_MAX_ST..12.35.',\n","       'KNEE Moment_X_MAX_ST_time..12.35.', 'KNEE Moment_X_MAX_ST..35.70.',\n","       'KNEE Moment_X_MAX_ST_time..35.70.', 'KNEE Power_X_MIN_SW',\n","       'KNEE Power_X_MIN_SW_time', 'KNEE Power_X_MAX_ST..12.35.',\n","       'KNEE Power_X_MAX_ST_time..12.35.', 'KNEE Power_X_MIN_ST..01.25.',\n","       'KNEE Power_X_MIN_ST_time..01.25.', 'KNEE Power_X_MIN_ST..35.70.',\n","       'KNEE Power_X_MIN_ST_time..35.70.', 'KNEE Power_X_MAX_ST..01.12.',\n","       'KNEE Power_X_MAX_ST_time..01.12.'],\n","      dtype='object')"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Remove the Columns: [\"Participant\", \"Side\"]- These columns were not needed.\n","df = df.drop([\"Participant\", \"Side\"], axis=1)\n","print(\"df.shape = \", df.shape)\n","df.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3HhJQHf1bwMQ","executionInfo":{"status":"ok","timestamp":1663250448015,"user_tz":180,"elapsed":9,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"2e308ba3-72b1-4b72-f57f-ea3967a6a306"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["df.shape =  (72, 37)\n"]},{"output_type":"execute_result","data":{"text/plain":["Index(['Group', 'ANKLE Moment_X_MAX_ST..35.70.',\n","       'ANKLE Moment_X_MAX_ST_time..35.70.', 'ANKLE Power_X_MAX_ST..35.70.',\n","       'ANKLE Power_X_MAX_ST_time..35.70.', 'HIP Moment_X_MAX_ST',\n","       'HIP Moment_X_MAX_ST_time', 'HIP Moment_X_MAX_SW',\n","       'HIP Moment_X_MAX_SW_time', 'HIP Moment_X_MIN_ST..35.70.',\n","       'HIP Moment_X_MIN_ST_time..35.70.', 'HIP Moment_Y_MAX_ST..12.35.',\n","       'HIP Moment_Y_MAX_ST_time..12.35.', 'HIP Moment_Y_MAX_ST..35.70.',\n","       'HIP Moment_Y_MAX_ST_time..35.70.', 'HIP Power_X_MAX_ST..12.35.',\n","       'HIP Power_X_MAX_ST_time..12.35.', 'HIP Power_X_MAX_ST..35.70.',\n","       'HIP Power_X_MAX_ST_time..35.70.', 'HIP Power_X_MIN_ST..35.70.',\n","       'HIP Power_X_MIN_ST_time..35.70.', 'KNEE Moment_X_MIN_ST',\n","       'KNEE Moment_X_MIN_ST_time', 'KNEE Moment_X_MAX_ST..12.35.',\n","       'KNEE Moment_X_MAX_ST_time..12.35.', 'KNEE Moment_X_MAX_ST..35.70.',\n","       'KNEE Moment_X_MAX_ST_time..35.70.', 'KNEE Power_X_MIN_SW',\n","       'KNEE Power_X_MIN_SW_time', 'KNEE Power_X_MAX_ST..12.35.',\n","       'KNEE Power_X_MAX_ST_time..12.35.', 'KNEE Power_X_MIN_ST..01.25.',\n","       'KNEE Power_X_MIN_ST_time..01.25.', 'KNEE Power_X_MIN_ST..35.70.',\n","       'KNEE Power_X_MIN_ST_time..35.70.', 'KNEE Power_X_MAX_ST..01.12.',\n","       'KNEE Power_X_MAX_ST_time..01.12.'],\n","      dtype='object')"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["### Label encode target variable - `y`"],"metadata":{"id":"IAZ8y0XbGd7p"}},{"cell_type":"code","source":["# First, look at the target variable\n","print(df.loc[:, \"Group\"].values.shape)\n","print(df.loc[:, \"Group\"].values)"],"metadata":{"id":"9X3t72ywGN9_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663250448016,"user_tz":180,"elapsed":8,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"272ae637-6f96-4692-aca3-48539eafc836"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["(72,)\n","['Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n"," 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y' 'Y'\n"," 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O'\n"," 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O' 'O']\n"]}]},{"cell_type":"code","source":["# Perform Data Preprocessing\n","# Label Encoding the class variables \n","# Here, we replace the \"Control\" and \"Autism\" keywords with 0 and 1 values, respectively.\n","df[\"Group\"] = df[\"Group\"].replace({'O': 0, 'Y': 1})\n","df.head(3)"],"metadata":{"id":"8xBnH2lKQCvN","colab":{"base_uri":"https://localhost:8080/","height":254},"executionInfo":{"status":"ok","timestamp":1663250448016,"user_tz":180,"elapsed":7,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"b8701759-5062-4889-fc0f-76328049d270"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Group  ANKLE Moment_X_MAX_ST..35.70.  ANKLE Moment_X_MAX_ST_time..35.70.  \\\n","0      1                         1.6513                              50.435   \n","1      1                         1.5483                              50.000   \n","2      1                         1.2021                              45.455   \n","\n","   ANKLE Power_X_MAX_ST..35.70.  ANKLE Power_X_MAX_ST_time..35.70.  \\\n","0                        4.4286                             55.652   \n","1                        4.5833                             56.140   \n","2                        2.9617                             52.525   \n","\n","   HIP Moment_X_MAX_ST  HIP Moment_X_MAX_ST_time  HIP Moment_X_MAX_SW  \\\n","0              0.22744                   0.86957              0.35350   \n","1              0.52977                   5.26320              0.39082   \n","2              0.50208                   6.06060              0.42453   \n","\n","   HIP Moment_X_MAX_SW_time  HIP Moment_X_MIN_ST..35.70.  ...  \\\n","0                    94.783                     -0.91131  ...   \n","1                    97.368                     -0.73814  ...   \n","2                    91.919                     -1.05820  ...   \n","\n","   KNEE Power_X_MIN_SW  KNEE Power_X_MIN_SW_time  KNEE Power_X_MAX_ST..12.35.  \\\n","0              -1.0523                    93.043                      0.31687   \n","1              -1.5960                    92.982                      0.37378   \n","2              -1.1166                    88.889                      0.60614   \n","\n","   KNEE Power_X_MAX_ST_time..12.35.  KNEE Power_X_MIN_ST..01.25.  \\\n","0                            22.609                     -0.85170   \n","1                            14.035                     -0.61892   \n","2                            16.162                     -0.97828   \n","\n","   KNEE Power_X_MIN_ST_time..01.25.  KNEE Power_X_MIN_ST..35.70.  \\\n","0                            9.5652                      -1.0244   \n","1                            9.6491                      -1.4494   \n","2                            8.0808                      -2.1391   \n","\n","   KNEE Power_X_MIN_ST_time..35.70.  KNEE Power_X_MAX_ST..01.12.  \\\n","0                            57.391                      0.24955   \n","1                            57.018                      0.35562   \n","2                            54.545                      0.23823   \n","\n","   KNEE Power_X_MAX_ST_time..01.12.  \n","0                           0.86957  \n","1                           0.87719  \n","2                           1.01010  \n","\n","[3 rows x 37 columns]"],"text/html":["\n","  <div id=\"df-e199757f-d24e-4484-92f6-629dabc6b347\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Group</th>\n","      <th>ANKLE Moment_X_MAX_ST..35.70.</th>\n","      <th>ANKLE Moment_X_MAX_ST_time..35.70.</th>\n","      <th>ANKLE Power_X_MAX_ST..35.70.</th>\n","      <th>ANKLE Power_X_MAX_ST_time..35.70.</th>\n","      <th>HIP Moment_X_MAX_ST</th>\n","      <th>HIP Moment_X_MAX_ST_time</th>\n","      <th>HIP Moment_X_MAX_SW</th>\n","      <th>HIP Moment_X_MAX_SW_time</th>\n","      <th>HIP Moment_X_MIN_ST..35.70.</th>\n","      <th>...</th>\n","      <th>KNEE Power_X_MIN_SW</th>\n","      <th>KNEE Power_X_MIN_SW_time</th>\n","      <th>KNEE Power_X_MAX_ST..12.35.</th>\n","      <th>KNEE Power_X_MAX_ST_time..12.35.</th>\n","      <th>KNEE Power_X_MIN_ST..01.25.</th>\n","      <th>KNEE Power_X_MIN_ST_time..01.25.</th>\n","      <th>KNEE Power_X_MIN_ST..35.70.</th>\n","      <th>KNEE Power_X_MIN_ST_time..35.70.</th>\n","      <th>KNEE Power_X_MAX_ST..01.12.</th>\n","      <th>KNEE Power_X_MAX_ST_time..01.12.</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1.6513</td>\n","      <td>50.435</td>\n","      <td>4.4286</td>\n","      <td>55.652</td>\n","      <td>0.22744</td>\n","      <td>0.86957</td>\n","      <td>0.35350</td>\n","      <td>94.783</td>\n","      <td>-0.91131</td>\n","      <td>...</td>\n","      <td>-1.0523</td>\n","      <td>93.043</td>\n","      <td>0.31687</td>\n","      <td>22.609</td>\n","      <td>-0.85170</td>\n","      <td>9.5652</td>\n","      <td>-1.0244</td>\n","      <td>57.391</td>\n","      <td>0.24955</td>\n","      <td>0.86957</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1.5483</td>\n","      <td>50.000</td>\n","      <td>4.5833</td>\n","      <td>56.140</td>\n","      <td>0.52977</td>\n","      <td>5.26320</td>\n","      <td>0.39082</td>\n","      <td>97.368</td>\n","      <td>-0.73814</td>\n","      <td>...</td>\n","      <td>-1.5960</td>\n","      <td>92.982</td>\n","      <td>0.37378</td>\n","      <td>14.035</td>\n","      <td>-0.61892</td>\n","      <td>9.6491</td>\n","      <td>-1.4494</td>\n","      <td>57.018</td>\n","      <td>0.35562</td>\n","      <td>0.87719</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>1.2021</td>\n","      <td>45.455</td>\n","      <td>2.9617</td>\n","      <td>52.525</td>\n","      <td>0.50208</td>\n","      <td>6.06060</td>\n","      <td>0.42453</td>\n","      <td>91.919</td>\n","      <td>-1.05820</td>\n","      <td>...</td>\n","      <td>-1.1166</td>\n","      <td>88.889</td>\n","      <td>0.60614</td>\n","      <td>16.162</td>\n","      <td>-0.97828</td>\n","      <td>8.0808</td>\n","      <td>-2.1391</td>\n","      <td>54.545</td>\n","      <td>0.23823</td>\n","      <td>1.01010</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows Ã— 37 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e199757f-d24e-4484-92f6-629dabc6b347')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e199757f-d24e-4484-92f6-629dabc6b347 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e199757f-d24e-4484-92f6-629dabc6b347');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# saving the target variables into `y` variable.\n","y = df.loc[:, \"Group\"].values\n","print(\"y.shape = \", y.shape)\n","print(\"y = \", y)"],"metadata":{"id":"UCCJC0V_PaEm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663250448016,"user_tz":180,"elapsed":6,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"251856f2-9c7a-41ed-913c-ec38559d71fa"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["y.shape =  (72,)\n","y =  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"]}]},{"cell_type":"code","source":["# Perform Data Preprocessing- Data Standardization\n","# Defining a Standard Scaler for scaling the values in the dataset\n","# in the range of [-a, +a], i.e. scale values to a smaller range.\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()"],"metadata":{"id":"XhVuQF0SFXro","executionInfo":{"status":"ok","timestamp":1663250448492,"user_tz":180,"elapsed":481,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"YJo8W22xA9u4","executionInfo":{"status":"ok","timestamp":1663250448492,"user_tz":180,"elapsed":4,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aecae2f4-88ff-4d4a-c98d-bea34ffc8afe"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(72, 37)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"RKaT_6lfkDZ9","executionInfo":{"status":"ok","timestamp":1663250448492,"user_tz":180,"elapsed":2,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"source":["# Define the different segments from dataset to be used.\n","segments = {\n","    'KINETICS': df.loc[:,'ANKLE Moment_X_MAX_ST..35.70.':'KNEE Power_X_MAX_ST_time..01.12.'],\n","}\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZldBrEE5kA2L","colab":{"base_uri":"https://localhost:8080/","height":334},"executionInfo":{"status":"ok","timestamp":1663250449236,"user_tz":180,"elapsed":4,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"1db91afb-0635-4bf8-8fb3-4805ae2b3436"},"source":["print(segments[\"KINETICS\"].shape)\n","segments[\"KINETICS\"].head()"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["(72, 36)\n"]},{"output_type":"execute_result","data":{"text/plain":["   ANKLE Moment_X_MAX_ST..35.70.  ANKLE Moment_X_MAX_ST_time..35.70.  \\\n","0                         1.6513                              50.435   \n","1                         1.5483                              50.000   \n","2                         1.2021                              45.455   \n","3                         1.3666                              46.000   \n","4                         1.4126                              46.903   \n","\n","   ANKLE Power_X_MAX_ST..35.70.  ANKLE Power_X_MAX_ST_time..35.70.  \\\n","0                        4.4286                             55.652   \n","1                        4.5833                             56.140   \n","2                        2.9617                             52.525   \n","3                        3.2444                             53.000   \n","4                        3.2861                             53.982   \n","\n","   HIP Moment_X_MAX_ST  HIP Moment_X_MAX_ST_time  HIP Moment_X_MAX_SW  \\\n","0              0.22744                   0.86957              0.35350   \n","1              0.52977                   5.26320              0.39082   \n","2              0.50208                   6.06060              0.42453   \n","3              0.62291                   5.00000              0.54590   \n","4              0.22335                   4.42480              0.22118   \n","\n","   HIP Moment_X_MAX_SW_time  HIP Moment_X_MIN_ST..35.70.  \\\n","0                    94.783                     -0.91131   \n","1                    97.368                     -0.73814   \n","2                    91.919                     -1.05820   \n","3                    95.000                     -1.13550   \n","4                    95.575                     -0.50891   \n","\n","   HIP Moment_X_MIN_ST_time..35.70.  ...  KNEE Power_X_MIN_SW  \\\n","0                            51.304  ...             -1.05230   \n","1                            54.386  ...             -1.59600   \n","2                            47.475  ...             -1.11660   \n","3                            48.000  ...             -1.47290   \n","4                            53.097  ...             -0.85151   \n","\n","   KNEE Power_X_MIN_SW_time  KNEE Power_X_MAX_ST..12.35.  \\\n","0                    93.043                      0.31687   \n","1                    92.982                      0.37378   \n","2                    88.889                      0.60614   \n","3                    90.000                      0.29247   \n","4                    90.265                      0.79264   \n","\n","   KNEE Power_X_MAX_ST_time..12.35.  KNEE Power_X_MIN_ST..01.25.  \\\n","0                            22.609                     -0.85170   \n","1                            14.035                     -0.61892   \n","2                            16.162                     -0.97828   \n","3                            15.000                     -0.87590   \n","4                            14.159                     -2.70820   \n","\n","   KNEE Power_X_MIN_ST_time..01.25.  KNEE Power_X_MIN_ST..35.70.  \\\n","0                            9.5652                      -1.0244   \n","1                            9.6491                      -1.4494   \n","2                            8.0808                      -2.1391   \n","3                            8.0000                      -1.3109   \n","4                            8.8496                      -1.1395   \n","\n","   KNEE Power_X_MIN_ST_time..35.70.  KNEE Power_X_MAX_ST..01.12.  \\\n","0                            57.391                      0.24955   \n","1                            57.018                      0.35562   \n","2                            54.545                      0.23823   \n","3                            55.000                      0.31108   \n","4                            55.752                      0.28169   \n","\n","   KNEE Power_X_MAX_ST_time..01.12.  \n","0                           0.86957  \n","1                           0.87719  \n","2                           1.01010  \n","3                           1.00000  \n","4                          12.38900  \n","\n","[5 rows x 36 columns]"],"text/html":["\n","  <div id=\"df-fb8f6fa4-2fc2-4715-8084-7f1bae611bd3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ANKLE Moment_X_MAX_ST..35.70.</th>\n","      <th>ANKLE Moment_X_MAX_ST_time..35.70.</th>\n","      <th>ANKLE Power_X_MAX_ST..35.70.</th>\n","      <th>ANKLE Power_X_MAX_ST_time..35.70.</th>\n","      <th>HIP Moment_X_MAX_ST</th>\n","      <th>HIP Moment_X_MAX_ST_time</th>\n","      <th>HIP Moment_X_MAX_SW</th>\n","      <th>HIP Moment_X_MAX_SW_time</th>\n","      <th>HIP Moment_X_MIN_ST..35.70.</th>\n","      <th>HIP Moment_X_MIN_ST_time..35.70.</th>\n","      <th>...</th>\n","      <th>KNEE Power_X_MIN_SW</th>\n","      <th>KNEE Power_X_MIN_SW_time</th>\n","      <th>KNEE Power_X_MAX_ST..12.35.</th>\n","      <th>KNEE Power_X_MAX_ST_time..12.35.</th>\n","      <th>KNEE Power_X_MIN_ST..01.25.</th>\n","      <th>KNEE Power_X_MIN_ST_time..01.25.</th>\n","      <th>KNEE Power_X_MIN_ST..35.70.</th>\n","      <th>KNEE Power_X_MIN_ST_time..35.70.</th>\n","      <th>KNEE Power_X_MAX_ST..01.12.</th>\n","      <th>KNEE Power_X_MAX_ST_time..01.12.</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.6513</td>\n","      <td>50.435</td>\n","      <td>4.4286</td>\n","      <td>55.652</td>\n","      <td>0.22744</td>\n","      <td>0.86957</td>\n","      <td>0.35350</td>\n","      <td>94.783</td>\n","      <td>-0.91131</td>\n","      <td>51.304</td>\n","      <td>...</td>\n","      <td>-1.05230</td>\n","      <td>93.043</td>\n","      <td>0.31687</td>\n","      <td>22.609</td>\n","      <td>-0.85170</td>\n","      <td>9.5652</td>\n","      <td>-1.0244</td>\n","      <td>57.391</td>\n","      <td>0.24955</td>\n","      <td>0.86957</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.5483</td>\n","      <td>50.000</td>\n","      <td>4.5833</td>\n","      <td>56.140</td>\n","      <td>0.52977</td>\n","      <td>5.26320</td>\n","      <td>0.39082</td>\n","      <td>97.368</td>\n","      <td>-0.73814</td>\n","      <td>54.386</td>\n","      <td>...</td>\n","      <td>-1.59600</td>\n","      <td>92.982</td>\n","      <td>0.37378</td>\n","      <td>14.035</td>\n","      <td>-0.61892</td>\n","      <td>9.6491</td>\n","      <td>-1.4494</td>\n","      <td>57.018</td>\n","      <td>0.35562</td>\n","      <td>0.87719</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.2021</td>\n","      <td>45.455</td>\n","      <td>2.9617</td>\n","      <td>52.525</td>\n","      <td>0.50208</td>\n","      <td>6.06060</td>\n","      <td>0.42453</td>\n","      <td>91.919</td>\n","      <td>-1.05820</td>\n","      <td>47.475</td>\n","      <td>...</td>\n","      <td>-1.11660</td>\n","      <td>88.889</td>\n","      <td>0.60614</td>\n","      <td>16.162</td>\n","      <td>-0.97828</td>\n","      <td>8.0808</td>\n","      <td>-2.1391</td>\n","      <td>54.545</td>\n","      <td>0.23823</td>\n","      <td>1.01010</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.3666</td>\n","      <td>46.000</td>\n","      <td>3.2444</td>\n","      <td>53.000</td>\n","      <td>0.62291</td>\n","      <td>5.00000</td>\n","      <td>0.54590</td>\n","      <td>95.000</td>\n","      <td>-1.13550</td>\n","      <td>48.000</td>\n","      <td>...</td>\n","      <td>-1.47290</td>\n","      <td>90.000</td>\n","      <td>0.29247</td>\n","      <td>15.000</td>\n","      <td>-0.87590</td>\n","      <td>8.0000</td>\n","      <td>-1.3109</td>\n","      <td>55.000</td>\n","      <td>0.31108</td>\n","      <td>1.00000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.4126</td>\n","      <td>46.903</td>\n","      <td>3.2861</td>\n","      <td>53.982</td>\n","      <td>0.22335</td>\n","      <td>4.42480</td>\n","      <td>0.22118</td>\n","      <td>95.575</td>\n","      <td>-0.50891</td>\n","      <td>53.097</td>\n","      <td>...</td>\n","      <td>-0.85151</td>\n","      <td>90.265</td>\n","      <td>0.79264</td>\n","      <td>14.159</td>\n","      <td>-2.70820</td>\n","      <td>8.8496</td>\n","      <td>-1.1395</td>\n","      <td>55.752</td>\n","      <td>0.28169</td>\n","      <td>12.38900</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 36 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb8f6fa4-2fc2-4715-8084-7f1bae611bd3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fb8f6fa4-2fc2-4715-8084-7f1bae611bd3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fb8f6fa4-2fc2-4715-8084-7f1bae611bd3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["segments[\"KINETICS\"].columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e6WKpNlJd9ix","executionInfo":{"status":"ok","timestamp":1663250450056,"user_tz":180,"elapsed":3,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"cf1ed406-4463-45d6-cddd-11714ce82ce8"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['ANKLE Moment_X_MAX_ST..35.70.', 'ANKLE Moment_X_MAX_ST_time..35.70.',\n","       'ANKLE Power_X_MAX_ST..35.70.', 'ANKLE Power_X_MAX_ST_time..35.70.',\n","       'HIP Moment_X_MAX_ST', 'HIP Moment_X_MAX_ST_time',\n","       'HIP Moment_X_MAX_SW', 'HIP Moment_X_MAX_SW_time',\n","       'HIP Moment_X_MIN_ST..35.70.', 'HIP Moment_X_MIN_ST_time..35.70.',\n","       'HIP Moment_Y_MAX_ST..12.35.', 'HIP Moment_Y_MAX_ST_time..12.35.',\n","       'HIP Moment_Y_MAX_ST..35.70.', 'HIP Moment_Y_MAX_ST_time..35.70.',\n","       'HIP Power_X_MAX_ST..12.35.', 'HIP Power_X_MAX_ST_time..12.35.',\n","       'HIP Power_X_MAX_ST..35.70.', 'HIP Power_X_MAX_ST_time..35.70.',\n","       'HIP Power_X_MIN_ST..35.70.', 'HIP Power_X_MIN_ST_time..35.70.',\n","       'KNEE Moment_X_MIN_ST', 'KNEE Moment_X_MIN_ST_time',\n","       'KNEE Moment_X_MAX_ST..12.35.', 'KNEE Moment_X_MAX_ST_time..12.35.',\n","       'KNEE Moment_X_MAX_ST..35.70.', 'KNEE Moment_X_MAX_ST_time..35.70.',\n","       'KNEE Power_X_MIN_SW', 'KNEE Power_X_MIN_SW_time',\n","       'KNEE Power_X_MAX_ST..12.35.', 'KNEE Power_X_MAX_ST_time..12.35.',\n","       'KNEE Power_X_MIN_ST..01.25.', 'KNEE Power_X_MIN_ST_time..01.25.',\n","       'KNEE Power_X_MIN_ST..35.70.', 'KNEE Power_X_MIN_ST_time..35.70.',\n","       'KNEE Power_X_MAX_ST..01.12.', 'KNEE Power_X_MAX_ST_time..01.12.'],\n","      dtype='object')"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["# Defining **Cross Validation** method to be used"],"metadata":{"id":"biPEsyGaJcCm"}},{"cell_type":"code","metadata":{"id":"bIc1szr7JT6v","executionInfo":{"status":"ok","timestamp":1663250451733,"user_tz":180,"elapsed":215,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"source":["# Define Leave-One-Out CV\n","from sklearn.model_selection import LeaveOneOut\n","loocv = LeaveOneOut()\n","\n","# # Define Repeated Stratified k-fold CV\n","# from sklearn.model_selection import cross_validate, RepeatedStratifiedKFold\n","# rskf_cv = RepeatedStratifiedKFold(n_splits=8, n_repeats=5, random_state=36851234)"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# Defning the **Classifer** to be used"],"metadata":{"id":"nloOMmfEJmU9"}},{"cell_type":"code","metadata":{"id":"j-3zxXyQJXvp","executionInfo":{"status":"ok","timestamp":1663252219924,"user_tz":180,"elapsed":4,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"source":["# Define the Classifier to be used for Sequential Feature Selection (SFS)\n","\n","# # Apply Linear LDA\n","# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","# lda = LinearDiscriminantAnalysis(solver='svd', n_components=None)\n","\n","# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n","# Define SVM classifier with RBF kernel\n","from sklearn.svm import SVC\n","svm = SVC(kernel='linear', C=90, verbose=False)\n"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["# Defining the **Feature Selection** algorithm to be used"],"metadata":{"id":"88qrPopzJxXR"}},{"cell_type":"code","source":["!pip install mlxtend --upgrade"],"metadata":{"id":"xlmQgooyazij","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663252225440,"user_tz":180,"elapsed":5519,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"711b7f25-8b68-4d92-ae21-822eba54486c"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.20.0)\n","Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.3.5)\n","Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (57.4.0)\n","Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.21.6)\n","Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n","Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.7.3)\n","Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.0.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.0.0->mlxtend) (4.1.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->mlxtend) (2022.2.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.0->mlxtend) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.2->mlxtend) (3.1.0)\n"]}]},{"cell_type":"code","metadata":{"id":"DHhmowQXJakc","executionInfo":{"status":"ok","timestamp":1663252225441,"user_tz":180,"elapsed":11,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"source":["# Define the Sequential Feature Selection class\n","# https://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/\n","\n","# Below is the code for applying Forward Feature Selection\n","from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n","sfs = SFS(estimator=svm, \n","            k_features=(1,15),\n","            forward=True, floating=False,\n","            verbose=2,\n","            scoring=('accuracy'),\n","            cv=loocv,\n","            n_jobs=-1)"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8LBBkwtMS7DT"},"source":["# **Hyper-Parameter Optimization** for Non-Linear SVC (RBF)"]},{"cell_type":"code","metadata":{"id":"-SlsUKmGS5sf","executionInfo":{"status":"ok","timestamp":1663252225441,"user_tz":180,"elapsed":9,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"source":["# Define the Classifier and Parameter Grid to be used for GridSearch and final Evaluation\n","# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n","from sklearn.svm import SVC\n","svm_classifier = SVC()\n","\n","param_grid = [\n","              {'C': [0.01, 0.1, 0, 0.5, 1, 2, 3, 5, 8, 20, 50, 90], \n","               'gamma': ['scale', 'auto', 0.01, 0.03, 0.04, 0.043, 0.045, 0.048, 0.05, 0.053, 0.055, 0.058, 0.06, 0.08, 0.0001, 0.001, 0.1, 1, 10], \n","               'tol':[1e-2, 1e-3, 1e-4, 1e-5], \n","               'kernel': ['linear']}, #rbfSVM\n","]"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HKXGSHqiSnrn"},"source":[":### Change the `estimator` in GridSearch to the estimator you are using."]},{"cell_type":"code","metadata":{"id":"oyCV260fSdpG","executionInfo":{"status":"ok","timestamp":1663252225441,"user_tz":180,"elapsed":9,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"source":["# Define Grid Search class\n","from sklearn.model_selection import GridSearchCV\n","gridSearch = GridSearchCV(estimator=svm_classifier, \n","                          param_grid=param_grid, \n","                          scoring='accuracy',\n","                          n_jobs=-1,\n","                          cv=loocv, # uses Leave One Out CV\n","                          refit=True, verbose=1)"],"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C_B0Iy5djqi1"},"source":["# Main Driver Code: **Non Linear SVM (RBF)**"]},{"cell_type":"code","metadata":{"id":"uqOUtRfMT4BR","executionInfo":{"status":"ok","timestamp":1663251358977,"user_tz":180,"elapsed":5,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"source":["# Type the name of the Algorithm that you are using\n","# This will be used while Writing the Scores in .txt file\n","# LDA, LinearSVM, SVM (RBF), SVM (polynomial), LogisticRegression, RandomForest\n","algorith_you_are_using = 'LinearSVM' "],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"HIlZTMMariR_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ee95d0b2-7f9f-43bf-9e79-ed06918d4951","executionInfo":{"status":"ok","timestamp":1663250756444,"user_tz":180,"elapsed":297068,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}}},"source":["'''svm = SVC(kernel='linear', verbose=False, C=1)'''\n","from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n","from utils import *\n","\n","for (key, value) in segments.items():\n","  print(\"Running: \", key)\n","\n","  X = value.values\n","  X = sc.fit_transform(X) # Apply Standard Scaler\n","  print(\"X.shape = \", X.shape)\n","\n","  # Apply Sequetial Forward Feature Selection (SFS)\n","  sfs.k_features = (1, X.shape[1])\n","  sfs.fit(X, y)\n","  print(\"\\nsfs.k_score_ = \", sfs.k_score_)\n","  print(\"sfs.k_feature_idx_ = \", sfs.k_feature_idx_)\n","  \n","  # Apply Grid Search on the Most Significant Parameters\n","  X = sfs.transform(X)\n","  print(\"[After SFS] X.shape = \", X.shape)\n","  search_results = gridSearch.fit(X, y)\n","  \n","  # Get the Best Classfier (Best Parameters) after Grid Search\n","  best_classifier = search_results.best_estimator_\n","  print(\"best_classifier = \", best_classifier)\n","  \n","  # Apply LOOCV to get classification scores\n","  y_true_list, y_pred_list = [], []\n","  for train_idx, test_idx in loocv.split(X, y):\n","      x_train, y_train = X[train_idx], y[train_idx]\n","      x_test, y_test = X[test_idx], y[test_idx]\n","      \n","      best_classifier.fit(x_train, y_train)\n","      \n","      y_pred = best_classifier.predict(x_test)\n","\n","      y_true_list.append(y_test[:])\n","      y_pred_list.append(y_pred[:])\n","  print(\"\\n##############################################################\\n\")\n","\n","  print(\"{}, {}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(algorith_you_are_using, \n","                                                                                          key, \n","                                                                                          accuracy_score(y_true_list, y_pred_list),\n","                                                                                          get_specificity(y_true_list, y_pred_list),\n","                                                                                          get_sensitivity(y_true_list, y_pred_list),\n","                                                                                          get_NPV(y_true_list, y_pred_list),\n","                                                                                          get_PPV(y_true_list, y_pred_list),\n","                                                                                          get_PLR(y_true_list, y_pred_list),\n","                                                                                          f1_score(y_true_list, y_pred_list, labels=[0, 1]),\n","                                                                                          get_MCC(y_true_list, y_pred_list)                                                                                               \n","                                                                                          ))\n","\n","  print(\"\\n##############################################################\")\n"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Running:  KINETICS\n","X.shape =  (72, 36)\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    6.7s finished\n","\n","[2022-09-15 14:01:05] Features: 1/36 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    5.8s finished\n","\n","[2022-09-15 14:01:11] Features: 2/36 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:    6.8s finished\n","\n","[2022-09-15 14:01:18] Features: 3/36 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    6.6s finished\n","\n","[2022-09-15 14:01:25] Features: 4/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    5.4s finished\n","\n","[2022-09-15 14:01:30] Features: 5/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:    5.1s finished\n","\n","[2022-09-15 14:01:35] Features: 6/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    6.0s finished\n","\n","[2022-09-15 14:01:41] Features: 7/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:    7.5s finished\n","\n","[2022-09-15 14:01:49] Features: 8/36 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:    6.4s finished\n","\n","[2022-09-15 14:01:55] Features: 9/36 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    3.1s finished\n","\n","[2022-09-15 14:01:58] Features: 10/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:    3.1s finished\n","\n","[2022-09-15 14:02:01] Features: 11/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    3.2s finished\n","\n","[2022-09-15 14:02:04] Features: 12/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    3.2s finished\n","\n","[2022-09-15 14:02:08] Features: 13/36 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    2.9s finished\n","\n","[2022-09-15 14:02:11] Features: 14/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    2.8s finished\n","\n","[2022-09-15 14:02:13] Features: 15/36 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    2.7s finished\n","\n","[2022-09-15 14:02:16] Features: 16/36 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    2.5s finished\n","\n","[2022-09-15 14:02:19] Features: 17/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    2.4s finished\n","\n","[2022-09-15 14:02:21] Features: 18/36 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    2.6s finished\n","\n","[2022-09-15 14:02:24] Features: 19/36 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    2.7s finished\n","\n","[2022-09-15 14:02:26] Features: 20/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    2.7s finished\n","\n","[2022-09-15 14:02:29] Features: 21/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    2.5s finished\n","\n","[2022-09-15 14:02:32] Features: 22/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    2.2s finished\n","\n","[2022-09-15 14:02:34] Features: 23/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    2.2s finished\n","\n","[2022-09-15 14:02:36] Features: 24/36 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    2.2s finished\n","\n","[2022-09-15 14:02:38] Features: 25/36 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    2.3s finished\n","\n","[2022-09-15 14:02:40] Features: 26/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.8s finished\n","\n","[2022-09-15 14:02:42] Features: 27/36 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    1.6s finished\n","\n","[2022-09-15 14:02:44] Features: 28/36 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    1.6s finished\n","\n","[2022-09-15 14:02:45] Features: 29/36 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    1.5s finished\n","\n","[2022-09-15 14:02:47] Features: 30/36 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    1.2s finished\n","\n","[2022-09-15 14:02:48] Features: 31/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.2s remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.2s finished\n","\n","[2022-09-15 14:02:49] Features: 32/36 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    1.0s remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    1.0s finished\n","\n","[2022-09-15 14:02:50] Features: 33/36 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.7s finished\n","\n","[2022-09-15 14:02:51] Features: 34/36 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.4s finished\n","\n","[2022-09-15 14:02:52] Features: 35/36 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.2s finished\n","\n","[2022-09-15 14:02:52] Features: 36/36 -- score: 0.7777777777777778"]},{"output_type":"stream","name":"stdout","text":["\n","sfs.k_score_ =  0.8888888888888888\n","sfs.k_feature_idx_ =  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35)\n","[After SFS] X.shape =  (72, 32)\n","Fitting 72 folds for each of 912 candidates, totalling 65664 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","5472 fits failed out of a total of 65664.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","5472 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 255, in fit\n","    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 333, in _dense_fit\n","    random_seed=random_seed,\n","  File \"sklearn/svm/_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n","ValueError: C <= 0\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.65277778 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778\n"," 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778\n"," 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778\n"," 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778\n"," 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778\n"," 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778\n"," 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778\n"," 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778\n"," 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778\n"," 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778\n"," 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778\n"," 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778 0.65277778\n"," 0.65277778 0.65277778 0.65277778 0.65277778 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n"," 0.81944444 0.80555556 0.80555556 0.80555556 0.81944444 0.80555556\n"," 0.80555556 0.80555556 0.81944444 0.80555556 0.80555556 0.80555556\n"," 0.81944444 0.80555556 0.80555556 0.80555556 0.81944444 0.80555556\n"," 0.80555556 0.80555556 0.81944444 0.80555556 0.80555556 0.80555556\n"," 0.81944444 0.80555556 0.80555556 0.80555556 0.81944444 0.80555556\n"," 0.80555556 0.80555556 0.81944444 0.80555556 0.80555556 0.80555556\n"," 0.81944444 0.80555556 0.80555556 0.80555556 0.81944444 0.80555556\n"," 0.80555556 0.80555556 0.81944444 0.80555556 0.80555556 0.80555556\n"," 0.81944444 0.80555556 0.80555556 0.80555556 0.81944444 0.80555556\n"," 0.80555556 0.80555556 0.81944444 0.80555556 0.80555556 0.80555556\n"," 0.81944444 0.80555556 0.80555556 0.80555556 0.81944444 0.80555556\n"," 0.80555556 0.80555556 0.81944444 0.80555556 0.80555556 0.80555556\n"," 0.81944444 0.80555556 0.80555556 0.80555556 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889 0.88888889\n"," 0.88888889 0.88888889 0.875      0.86111111 0.86111111 0.86111111\n"," 0.875      0.86111111 0.86111111 0.86111111 0.875      0.86111111\n"," 0.86111111 0.86111111 0.875      0.86111111 0.86111111 0.86111111\n"," 0.875      0.86111111 0.86111111 0.86111111 0.875      0.86111111\n"," 0.86111111 0.86111111 0.875      0.86111111 0.86111111 0.86111111\n"," 0.875      0.86111111 0.86111111 0.86111111 0.875      0.86111111\n"," 0.86111111 0.86111111 0.875      0.86111111 0.86111111 0.86111111\n"," 0.875      0.86111111 0.86111111 0.86111111 0.875      0.86111111\n"," 0.86111111 0.86111111 0.875      0.86111111 0.86111111 0.86111111\n"," 0.875      0.86111111 0.86111111 0.86111111 0.875      0.86111111\n"," 0.86111111 0.86111111 0.875      0.86111111 0.86111111 0.86111111\n"," 0.875      0.86111111 0.86111111 0.86111111 0.875      0.86111111\n"," 0.86111111 0.86111111 0.875      0.86111111 0.86111111 0.86111111\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333]\n","  category=UserWarning,\n"]},{"output_type":"stream","name":"stdout","text":["best_classifier =  SVC(C=1, kernel='linear', tol=0.01)\n","\n","##############################################################\n","\n","LinearSVM, KINETICS, 0.889, 0.889, 0.889, 0.889, 0.889, 8.000, 0.889, 0.778\n","\n","##############################################################\n"]}]},{"cell_type":"code","source":["'''svm = SVC(kernel='linear', C=30, verbose=False)'''\n","from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n","from utils import *\n","\n","for (key, value) in segments.items():\n","  print(\"Running: \", key)\n","\n","  X = value.values\n","  X = sc.fit_transform(X) # Apply Standard Scaler\n","  print(\"X.shape = \", X.shape)\n","\n","  # Apply Sequetial Forward Feature Selection (SFS)\n","  sfs.k_features = (1, X.shape[1])\n","  sfs.fit(X, y)\n","  print(\"\\nsfs.k_score_ = \", sfs.k_score_)\n","  print(\"sfs.k_feature_idx_ = \", sfs.k_feature_idx_)\n","  \n","  # Apply Grid Search on the Most Significant Parameters\n","  X = sfs.transform(X)\n","  print(\"[After SFS] X.shape = \", X.shape)\n","  search_results = gridSearch.fit(X, y)\n","  \n","  # Get the Best Classfier (Best Parameters) after Grid Search\n","  best_classifier = search_results.best_estimator_\n","  print(\"best_classifier = \", best_classifier)\n","  \n","  # Apply LOOCV to get classification scores\n","  y_true_list, y_pred_list = [], []\n","  for train_idx, test_idx in loocv.split(X, y):\n","      x_train, y_train = X[train_idx], y[train_idx]\n","      x_test, y_test = X[test_idx], y[test_idx]\n","      \n","      best_classifier.fit(x_train, y_train)\n","      \n","      y_pred = best_classifier.predict(x_test)\n","\n","      y_true_list.append(y_test[:])\n","      y_pred_list.append(y_pred[:])\n","  print(\"\\n##############################################################\\n\")\n","\n","  print(\"{}, {}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(algorith_you_are_using, \n","                                                                                          key, \n","                                                                                          accuracy_score(y_true_list, y_pred_list),\n","                                                                                          get_specificity(y_true_list, y_pred_list),\n","                                                                                          get_sensitivity(y_true_list, y_pred_list),\n","                                                                                          get_NPV(y_true_list, y_pred_list),\n","                                                                                          get_PPV(y_true_list, y_pred_list),\n","                                                                                          get_PLR(y_true_list, y_pred_list),\n","                                                                                          f1_score(y_true_list, y_pred_list, labels=[0, 1]),\n","                                                                                          get_MCC(y_true_list, y_pred_list)                                                                                               \n","                                                                                          ))\n","\n","  print(\"\\n##############################################################\")\n"],"metadata":{"id":"_7XAcpz6hof5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663251354377,"user_tz":180,"elapsed":594359,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"629869e5-991f-4c1e-9b4d-8aea1f5ec3e7"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Running:  KINETICS\n","X.shape =  (72, 36)\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    5.2s finished\n","\n","[2022-09-15 14:06:04] Features: 1/36 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    8.8s finished\n","\n","[2022-09-15 14:06:13] Features: 2/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:    9.1s finished\n","\n","[2022-09-15 14:06:22] Features: 3/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    6.9s finished\n","\n","[2022-09-15 14:06:29] Features: 4/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    5.6s finished\n","\n","[2022-09-15 14:06:35] Features: 5/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:    7.3s finished\n","\n","[2022-09-15 14:06:42] Features: 6/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    9.1s finished\n","\n","[2022-09-15 14:06:51] Features: 7/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:   11.0s finished\n","\n","[2022-09-15 14:07:02] Features: 8/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:   14.4s finished\n","\n","[2022-09-15 14:07:17] Features: 9/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   13.2s finished\n","\n","[2022-09-15 14:07:30] Features: 10/36 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:   18.7s finished\n","\n","[2022-09-15 14:07:48] Features: 11/36 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   24.7s finished\n","\n","[2022-09-15 14:08:13] Features: 12/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   22.2s finished\n","\n","[2022-09-15 14:08:35] Features: 13/36 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:   24.9s finished\n","\n","[2022-09-15 14:09:00] Features: 14/36 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:   25.1s finished\n","\n","[2022-09-15 14:09:25] Features: 15/36 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:   28.0s finished\n","\n","[2022-09-15 14:09:53] Features: 16/36 -- score: 0.7916666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   24.1s finished\n","\n","[2022-09-15 14:10:17] Features: 17/36 -- score: 0.75[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:   20.5s finished\n","\n","[2022-09-15 14:10:38] Features: 18/36 -- score: 0.7222222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:   21.6s finished\n","\n","[2022-09-15 14:11:00] Features: 19/36 -- score: 0.7361111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:   17.1s finished\n","\n","[2022-09-15 14:11:17] Features: 20/36 -- score: 0.7361111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:   20.1s finished\n","\n","[2022-09-15 14:11:37] Features: 21/36 -- score: 0.7222222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   18.8s finished\n","\n","[2022-09-15 14:11:56] Features: 22/36 -- score: 0.7222222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:   16.3s finished\n","\n","[2022-09-15 14:12:12] Features: 23/36 -- score: 0.6944444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    9.5s finished\n","\n","[2022-09-15 14:12:21] Features: 24/36 -- score: 0.7083333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    5.2s finished\n","\n","[2022-09-15 14:12:27] Features: 25/36 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    3.4s finished\n","\n","[2022-09-15 14:12:30] Features: 26/36 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.3s finished\n","\n","[2022-09-15 14:12:32] Features: 27/36 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    1.9s finished\n","\n","[2022-09-15 14:12:34] Features: 28/36 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    2.1s finished\n","\n","[2022-09-15 14:12:36] Features: 29/36 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    1.8s finished\n","\n","[2022-09-15 14:12:38] Features: 30/36 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    1.5s finished\n","\n","[2022-09-15 14:12:40] Features: 31/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.1s remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.2s finished\n","\n","[2022-09-15 14:12:41] Features: 32/36 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.8s remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.8s finished\n","\n","[2022-09-15 14:12:41] Features: 33/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.5s finished\n","\n","[2022-09-15 14:12:42] Features: 34/36 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.4s finished\n","\n","[2022-09-15 14:12:42] Features: 35/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.2s finished\n","\n","[2022-09-15 14:12:43] Features: 36/36 -- score: 0.8055555555555556"]},{"output_type":"stream","name":"stdout","text":["\n","sfs.k_score_ =  0.9027777777777778\n","sfs.k_feature_idx_ =  (0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 34, 35)\n","[After SFS] X.shape =  (72, 29)\n","Fitting 72 folds for each of 912 candidates, totalling 65664 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","5472 fits failed out of a total of 65664.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","5472 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 255, in fit\n","    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 333, in _dense_fit\n","    random_seed=random_seed,\n","  File \"sklearn/svm/_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n","ValueError: C <= 0\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.75       0.75\n"," 0.75       0.75       0.75       0.75       0.75       0.75\n"," 0.75       0.75       0.75       0.75       0.75       0.75\n"," 0.75       0.75       0.75       0.75       0.75       0.75\n"," 0.75       0.75       0.75       0.75       0.75       0.75\n"," 0.75       0.75       0.75       0.75       0.75       0.75\n"," 0.75       0.75       0.75       0.75       0.75       0.75\n"," 0.75       0.75       0.75       0.75       0.75       0.75\n"," 0.75       0.75       0.75       0.75       0.75       0.75\n"," 0.75       0.75       0.75       0.75       0.75       0.75\n"," 0.75       0.75       0.75       0.75       0.75       0.75\n"," 0.75       0.75       0.75       0.75       0.75       0.75\n"," 0.75       0.75       0.75       0.75       0.75       0.75\n"," 0.75       0.75              nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444 0.69444444\n"," 0.69444444 0.69444444 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889 0.76388889\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778\n"," 0.88888889 0.90277778 0.90277778 0.90277778 0.88888889 0.90277778\n"," 0.90277778 0.90277778 0.88888889 0.90277778 0.90277778 0.90277778]\n","  category=UserWarning,\n"]},{"output_type":"stream","name":"stdout","text":["best_classifier =  SVC(C=5, kernel='linear')\n","\n","##############################################################\n","\n","LinearSVM, KINETICS, 0.903, 0.917, 0.889, 0.892, 0.914, 10.667, 0.901, 0.806\n","\n","##############################################################\n"]}]},{"cell_type":"code","source":["'''svm = SVC(kernel='linear', C=60, verbose=False)'''\n","from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n","from utils import *\n","\n","for (key, value) in segments.items():\n","  print(\"Running: \", key)\n","\n","  X = value.values\n","  X = sc.fit_transform(X) # Apply Standard Scaler\n","  print(\"X.shape = \", X.shape)\n","\n","  # Apply Sequetial Forward Feature Selection (SFS)\n","  sfs.k_features = (1, X.shape[1])\n","  sfs.fit(X, y)\n","  print(\"\\nsfs.k_score_ = \", sfs.k_score_)\n","  print(\"sfs.k_feature_idx_ = \", sfs.k_feature_idx_)\n","  \n","  # Apply Grid Search on the Most Significant Parameters\n","  X = sfs.transform(X)\n","  print(\"[After SFS] X.shape = \", X.shape)\n","  search_results = gridSearch.fit(X, y)\n","  \n","  # Get the Best Classfier (Best Parameters) after Grid Search\n","  best_classifier = search_results.best_estimator_\n","  print(\"best_classifier = \", best_classifier)\n","  \n","  # Apply LOOCV to get classification scores\n","  y_true_list, y_pred_list = [], []\n","  for train_idx, test_idx in loocv.split(X, y):\n","      x_train, y_train = X[train_idx], y[train_idx]\n","      x_test, y_test = X[test_idx], y[test_idx]\n","      \n","      best_classifier.fit(x_train, y_train)\n","      \n","      y_pred = best_classifier.predict(x_test)\n","\n","      y_true_list.append(y_test[:])\n","      y_pred_list.append(y_pred[:])\n","  print(\"\\n##############################################################\\n\")\n","\n","  print(\"{}, {}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(algorith_you_are_using, \n","                                                                                          key, \n","                                                                                          accuracy_score(y_true_list, y_pred_list),\n","                                                                                          get_specificity(y_true_list, y_pred_list),\n","                                                                                          get_sensitivity(y_true_list, y_pred_list),\n","                                                                                          get_NPV(y_true_list, y_pred_list),\n","                                                                                          get_PPV(y_true_list, y_pred_list),\n","                                                                                          get_PLR(y_true_list, y_pred_list),\n","                                                                                          f1_score(y_true_list, y_pred_list, labels=[0, 1]),\n","                                                                                          get_MCC(y_true_list, y_pred_list)                                                                                               \n","                                                                                          ))\n","\n","  print(\"\\n##############################################################\")\n"],"metadata":{"id":"QynMgXGkg_TN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663252219755,"user_tz":180,"elapsed":860783,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"473b8f8a-fed2-4322-fed3-afe267ac403a"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Running:  KINETICS\n","X.shape =  (72, 36)\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    5.3s finished\n","\n","[2022-09-15 14:16:03] Features: 1/36 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    9.8s finished\n","\n","[2022-09-15 14:16:13] Features: 2/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:   10.2s finished\n","\n","[2022-09-15 14:16:23] Features: 3/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    7.7s finished\n","\n","[2022-09-15 14:16:31] Features: 4/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    7.9s finished\n","\n","[2022-09-15 14:16:39] Features: 5/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:   12.2s finished\n","\n","[2022-09-15 14:16:51] Features: 6/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   17.8s finished\n","\n","[2022-09-15 14:17:09] Features: 7/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:   19.9s finished\n","\n","[2022-09-15 14:17:29] Features: 8/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:   25.7s finished\n","\n","[2022-09-15 14:17:55] Features: 9/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   24.3s finished\n","\n","[2022-09-15 14:18:19] Features: 10/36 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:   34.7s finished\n","\n","[2022-09-15 14:18:54] Features: 11/36 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   44.5s finished\n","\n","[2022-09-15 14:19:38] Features: 12/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   44.6s finished\n","\n","[2022-09-15 14:20:23] Features: 13/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:   49.4s finished\n","\n","[2022-09-15 14:21:12] Features: 14/36 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:   48.2s finished\n","\n","[2022-09-15 14:22:01] Features: 15/36 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:   53.6s finished\n","\n","[2022-09-15 14:22:54] Features: 16/36 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   48.9s finished\n","\n","[2022-09-15 14:23:43] Features: 17/36 -- score: 0.75[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:   39.2s finished\n","\n","[2022-09-15 14:24:22] Features: 18/36 -- score: 0.7222222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:   41.9s finished\n","\n","[2022-09-15 14:25:04] Features: 19/36 -- score: 0.7361111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:   32.8s finished\n","\n","[2022-09-15 14:25:37] Features: 20/36 -- score: 0.7361111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:   42.0s finished\n","\n","[2022-09-15 14:26:19] Features: 21/36 -- score: 0.7083333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   21.0s finished\n","\n","[2022-09-15 14:26:40] Features: 22/36 -- score: 0.7916666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    5.0s finished\n","\n","[2022-09-15 14:26:45] Features: 23/36 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    3.0s finished\n","\n","[2022-09-15 14:26:48] Features: 24/36 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    3.0s finished\n","\n","[2022-09-15 14:26:51] Features: 25/36 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    2.5s finished\n","\n","[2022-09-15 14:26:53] Features: 26/36 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.1s finished\n","\n","[2022-09-15 14:26:56] Features: 27/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    2.4s finished\n","\n","[2022-09-15 14:26:58] Features: 28/36 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    1.5s finished\n","\n","[2022-09-15 14:26:59] Features: 29/36 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    1.3s finished\n","\n","[2022-09-15 14:27:01] Features: 30/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    1.3s finished\n","\n","[2022-09-15 14:27:02] Features: 31/36 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.2s remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.2s finished\n","\n","[2022-09-15 14:27:03] Features: 32/36 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.8s remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.8s finished\n","\n","[2022-09-15 14:27:04] Features: 33/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.6s finished\n","\n","[2022-09-15 14:27:05] Features: 34/36 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.4s finished\n","\n","[2022-09-15 14:27:05] Features: 35/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.2s finished\n","\n","[2022-09-15 14:27:05] Features: 36/36 -- score: 0.8055555555555556"]},{"output_type":"stream","name":"stdout","text":["\n","sfs.k_score_ =  0.9027777777777778\n","sfs.k_feature_idx_ =  (0, 1, 4, 5, 6, 9, 10, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 32, 34, 35)\n","[After SFS] X.shape =  (72, 24)\n","Fitting 72 folds for each of 912 candidates, totalling 65664 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","5472 fits failed out of a total of 65664.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","5472 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 255, in fit\n","    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 333, in _dense_fit\n","    random_seed=random_seed,\n","  File \"sklearn/svm/_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n","ValueError: C <= 0\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.625      0.625\n"," 0.625      0.625      0.625      0.625      0.72222222 0.72222222\n"," 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222\n"," 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222\n"," 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222\n"," 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222\n"," 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222\n"," 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222\n"," 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222\n"," 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222\n"," 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222\n"," 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222\n"," 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222\n"," 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222 0.72222222\n"," 0.72222222 0.72222222        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556 0.80555556\n"," 0.83333333 0.81944444 0.81944444 0.81944444 0.83333333 0.81944444\n"," 0.81944444 0.81944444 0.83333333 0.81944444 0.81944444 0.81944444\n"," 0.83333333 0.81944444 0.81944444 0.81944444 0.83333333 0.81944444\n"," 0.81944444 0.81944444 0.83333333 0.81944444 0.81944444 0.81944444\n"," 0.83333333 0.81944444 0.81944444 0.81944444 0.83333333 0.81944444\n"," 0.81944444 0.81944444 0.83333333 0.81944444 0.81944444 0.81944444\n"," 0.83333333 0.81944444 0.81944444 0.81944444 0.83333333 0.81944444\n"," 0.81944444 0.81944444 0.83333333 0.81944444 0.81944444 0.81944444\n"," 0.83333333 0.81944444 0.81944444 0.81944444 0.83333333 0.81944444\n"," 0.81944444 0.81944444 0.83333333 0.81944444 0.81944444 0.81944444\n"," 0.83333333 0.81944444 0.81944444 0.81944444 0.83333333 0.81944444\n"," 0.81944444 0.81944444 0.83333333 0.81944444 0.81944444 0.81944444\n"," 0.83333333 0.81944444 0.81944444 0.81944444 0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.875      0.875      0.875      0.875\n"," 0.875      0.875      0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778\n"," 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778 0.90277778]\n","  category=UserWarning,\n"]},{"output_type":"stream","name":"stdout","text":["best_classifier =  SVC(C=8, kernel='linear', tol=0.01)\n","\n","##############################################################\n","\n","LinearSVM, KINETICS, 0.903, 0.917, 0.889, 0.892, 0.914, 10.667, 0.901, 0.806\n","\n","##############################################################\n"]}]},{"cell_type":"code","source":["'''svm = SVC(kernel='linear', verbose=False, C=90)'''\n","from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n","from utils import *\n","\n","for (key, value) in segments.items():\n","  print(\"Running: \", key)\n","\n","  X = value.values\n","  X = sc.fit_transform(X) # Apply Standard Scaler\n","  print(\"X.shape = \", X.shape)\n","\n","  # Apply Sequetial Forward Feature Selection (SFS)\n","  sfs.k_features = (1, X.shape[1])\n","  sfs.fit(X, y)\n","  print(\"\\nsfs.k_score_ = \", sfs.k_score_)\n","  print(\"sfs.k_feature_idx_ = \", sfs.k_feature_idx_)\n","  \n","  # Apply Grid Search on the Most Significant Parameters\n","  X = sfs.transform(X)\n","  print(\"[After SFS] X.shape = \", X.shape)\n","  search_results = gridSearch.fit(X, y)\n","  \n","  # Get the Best Classfier (Best Parameters) after Grid Search\n","  best_classifier = search_results.best_estimator_\n","  print(\"best_classifier = \", best_classifier)\n","  \n","  # Apply LOOCV to get classification scores\n","  y_true_list, y_pred_list = [], []\n","  for train_idx, test_idx in loocv.split(X, y):\n","      x_train, y_train = X[train_idx], y[train_idx]\n","      x_test, y_test = X[test_idx], y[test_idx]\n","      \n","      best_classifier.fit(x_train, y_train)\n","      \n","      y_pred = best_classifier.predict(x_test)\n","\n","      y_true_list.append(y_test[:])\n","      y_pred_list.append(y_pred[:])\n","  print(\"\\n##############################################################\\n\")\n","\n","  print(\"{}, {}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(algorith_you_are_using, \n","                                                                                          key, \n","                                                                                          accuracy_score(y_true_list, y_pred_list),\n","                                                                                          get_specificity(y_true_list, y_pred_list),\n","                                                                                          get_sensitivity(y_true_list, y_pred_list),\n","                                                                                          get_NPV(y_true_list, y_pred_list),\n","                                                                                          get_PPV(y_true_list, y_pred_list),\n","                                                                                          get_PLR(y_true_list, y_pred_list),\n","                                                                                          f1_score(y_true_list, y_pred_list, labels=[0, 1]),\n","                                                                                          get_MCC(y_true_list, y_pred_list)                                                                                               \n","                                                                                          ))\n","\n","  print(\"\\n##############################################################\")\n"],"metadata":{"id":"5N9wrGu3EwMe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663253105594,"user_tz":180,"elapsed":880161,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"f1e7ebb7-4f57-4234-88cf-daaf9cb2843b"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Running:  KINETICS\n","X.shape =  (72, 36)\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    6.5s finished\n","\n","[2022-09-15 14:30:31] Features: 1/36 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:   11.9s finished\n","\n","[2022-09-15 14:30:43] Features: 2/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:   10.0s finished\n","\n","[2022-09-15 14:30:53] Features: 3/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    9.2s finished\n","\n","[2022-09-15 14:31:02] Features: 4/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:   10.3s finished\n","\n","[2022-09-15 14:31:12] Features: 5/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:   15.8s finished\n","\n","[2022-09-15 14:31:28] Features: 6/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   22.3s finished\n","\n","[2022-09-15 14:31:50] Features: 7/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:   28.2s finished\n","\n","[2022-09-15 14:32:19] Features: 8/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:   35.1s finished\n","\n","[2022-09-15 14:32:54] Features: 9/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   36.7s finished\n","\n","[2022-09-15 14:33:31] Features: 10/36 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:   43.9s finished\n","\n","[2022-09-15 14:34:14] Features: 11/36 -- score: 0.7916666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   48.1s finished\n","\n","[2022-09-15 14:35:03] Features: 12/36 -- score: 0.7916666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:   41.6s finished\n","\n","[2022-09-15 14:35:44] Features: 13/36 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:   45.9s finished\n","\n","[2022-09-15 14:36:30] Features: 14/36 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:   45.0s finished\n","\n","[2022-09-15 14:37:15] Features: 15/36 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:   52.9s finished\n","\n","[2022-09-15 14:38:08] Features: 16/36 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   60.0s finished\n","\n","[2022-09-15 14:39:08] Features: 17/36 -- score: 0.7638888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:  1.1min finished\n","\n","[2022-09-15 14:40:12] Features: 18/36 -- score: 0.75[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:   44.9s finished\n","\n","[2022-09-15 14:40:57] Features: 19/36 -- score: 0.75[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:   11.3s finished\n","\n","[2022-09-15 14:41:08] Features: 20/36 -- score: 0.8888888888888888[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    6.4s finished\n","\n","[2022-09-15 14:41:15] Features: 21/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    5.2s finished\n","\n","[2022-09-15 14:41:20] Features: 22/36 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    5.7s finished\n","\n","[2022-09-15 14:41:26] Features: 23/36 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    5.9s finished\n","\n","[2022-09-15 14:41:32] Features: 24/36 -- score: 0.7777777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    4.9s finished\n","\n","[2022-09-15 14:41:37] Features: 25/36 -- score: 0.8472222222222222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    3.9s finished\n","\n","[2022-09-15 14:41:40] Features: 26/36 -- score: 0.8194444444444444[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.6s finished\n","\n","[2022-09-15 14:41:43] Features: 27/36 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    2.6s finished\n","\n","[2022-09-15 14:41:46] Features: 28/36 -- score: 0.8055555555555556[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    2.0s finished\n","\n","[2022-09-15 14:41:48] Features: 29/36 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    1.8s finished\n","\n","[2022-09-15 14:41:50] Features: 30/36 -- score: 0.8611111111111112[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    1.7s finished\n","\n","[2022-09-15 14:41:51] Features: 31/36 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.1s remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.1s finished\n","\n","[2022-09-15 14:41:52] Features: 32/36 -- score: 0.9166666666666666[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.9s remaining:    0.0s\n","[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.9s finished\n","\n","[2022-09-15 14:41:53] Features: 33/36 -- score: 0.9027777777777778[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.9s finished\n","\n","[2022-09-15 14:41:54] Features: 34/36 -- score: 0.875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.5s finished\n","\n","[2022-09-15 14:41:55] Features: 35/36 -- score: 0.8333333333333334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.2s finished\n","\n","[2022-09-15 14:41:55] Features: 36/36 -- score: 0.8055555555555556"]},{"output_type":"stream","name":"stdout","text":["\n","sfs.k_score_ =  0.9166666666666666\n","sfs.k_feature_idx_ =  (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33)\n","[After SFS] X.shape =  (72, 32)\n","Fitting 72 folds for each of 912 candidates, totalling 65664 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","5472 fits failed out of a total of 65664.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","5472 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 255, in fit\n","    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 333, in _dense_fit\n","    random_seed=random_seed,\n","  File \"sklearn/svm/_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n","ValueError: C <= 0\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n"," 0.84722222 0.83333333 0.83333333 0.83333333 0.84722222 0.83333333\n"," 0.83333333 0.83333333 0.84722222 0.83333333 0.83333333 0.83333333\n"," 0.84722222 0.83333333 0.83333333 0.83333333 0.84722222 0.83333333\n"," 0.83333333 0.83333333 0.84722222 0.83333333 0.83333333 0.83333333\n"," 0.84722222 0.83333333 0.83333333 0.83333333 0.84722222 0.83333333\n"," 0.83333333 0.83333333 0.84722222 0.83333333 0.83333333 0.83333333\n"," 0.84722222 0.83333333 0.83333333 0.83333333 0.84722222 0.83333333\n"," 0.83333333 0.83333333 0.84722222 0.83333333 0.83333333 0.83333333\n"," 0.84722222 0.83333333 0.83333333 0.83333333 0.84722222 0.83333333\n"," 0.83333333 0.83333333 0.84722222 0.83333333 0.83333333 0.83333333\n"," 0.84722222 0.83333333 0.83333333 0.83333333 0.84722222 0.83333333\n"," 0.83333333 0.83333333 0.84722222 0.83333333 0.83333333 0.83333333\n"," 0.84722222 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667]\n","  category=UserWarning,\n"]},{"output_type":"stream","name":"stdout","text":["best_classifier =  SVC(C=2, kernel='linear', tol=0.01)\n","\n","##############################################################\n","\n","LinearSVM, KINETICS, 0.917, 0.917, 0.917, 0.917, 0.917, 11.000, 0.917, 0.833\n","\n","##############################################################\n"]}]},{"cell_type":"markdown","metadata":{"id":"begowljae4wE"},"source":["# **Verification**"]},{"cell_type":"code","source":["# get the names of the feature subset selected using the Feature Selection algorithm.\n","sfs_feature_idx = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33]\n","print(\"Number of Features selected: \", len(sfs_feature_idx))\n","\n","segments[\"KINETICS\"].iloc[:, sfs_feature_idx].head()"],"metadata":{"id":"5zc0runCO1oW","colab":{"base_uri":"https://localhost:8080/","height":334},"executionInfo":{"status":"ok","timestamp":1663253265934,"user_tz":180,"elapsed":207,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"3760c448-a77d-46f0-89c5-7762a48e4205"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Features selected:  32\n"]},{"output_type":"execute_result","data":{"text/plain":["   ANKLE Moment_X_MAX_ST..35.70.  ANKLE Moment_X_MAX_ST_time..35.70.  \\\n","0                         1.6513                              50.435   \n","1                         1.5483                              50.000   \n","2                         1.2021                              45.455   \n","3                         1.3666                              46.000   \n","4                         1.4126                              46.903   \n","\n","   ANKLE Power_X_MAX_ST..35.70.  ANKLE Power_X_MAX_ST_time..35.70.  \\\n","0                        4.4286                             55.652   \n","1                        4.5833                             56.140   \n","2                        2.9617                             52.525   \n","3                        3.2444                             53.000   \n","4                        3.2861                             53.982   \n","\n","   HIP Moment_X_MAX_ST  HIP Moment_X_MAX_ST_time  HIP Moment_X_MAX_SW  \\\n","0              0.22744                   0.86957              0.35350   \n","1              0.52977                   5.26320              0.39082   \n","2              0.50208                   6.06060              0.42453   \n","3              0.62291                   5.00000              0.54590   \n","4              0.22335                   4.42480              0.22118   \n","\n","   HIP Moment_X_MAX_SW_time  HIP Moment_X_MIN_ST..35.70.  \\\n","0                    94.783                     -0.91131   \n","1                    97.368                     -0.73814   \n","2                    91.919                     -1.05820   \n","3                    95.000                     -1.13550   \n","4                    95.575                     -0.50891   \n","\n","   HIP Moment_X_MIN_ST_time..35.70.  ...  KNEE Moment_X_MAX_ST_time..12.35.  \\\n","0                            51.304  ...                             13.043   \n","1                            54.386  ...                             12.281   \n","2                            47.475  ...                             12.121   \n","3                            48.000  ...                             15.000   \n","4                            53.097  ...                             12.389   \n","\n","   KNEE Moment_X_MAX_ST..35.70.  KNEE Moment_X_MAX_ST_time..35.70.  \\\n","0                       0.26139                             57.391   \n","1                       0.30982                             57.018   \n","2                       0.50550                             53.535   \n","3                       0.38262                             53.000   \n","4                       0.30479                             54.867   \n","\n","   KNEE Power_X_MIN_SW  KNEE Power_X_MIN_SW_time  KNEE Power_X_MAX_ST..12.35.  \\\n","0             -1.05230                    93.043                      0.31687   \n","1             -1.59600                    92.982                      0.37378   \n","2             -1.11660                    88.889                      0.60614   \n","3             -1.47290                    90.000                      0.29247   \n","4             -0.85151                    90.265                      0.79264   \n","\n","   KNEE Power_X_MAX_ST_time..12.35.  KNEE Power_X_MIN_ST_time..01.25.  \\\n","0                            22.609                            9.5652   \n","1                            14.035                            9.6491   \n","2                            16.162                            8.0808   \n","3                            15.000                            8.0000   \n","4                            14.159                            8.8496   \n","\n","   KNEE Power_X_MIN_ST..35.70.  KNEE Power_X_MIN_ST_time..35.70.  \n","0                      -1.0244                            57.391  \n","1                      -1.4494                            57.018  \n","2                      -2.1391                            54.545  \n","3                      -1.3109                            55.000  \n","4                      -1.1395                            55.752  \n","\n","[5 rows x 32 columns]"],"text/html":["\n","  <div id=\"df-d012e966-e362-4b75-8eb1-7316cab734c3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ANKLE Moment_X_MAX_ST..35.70.</th>\n","      <th>ANKLE Moment_X_MAX_ST_time..35.70.</th>\n","      <th>ANKLE Power_X_MAX_ST..35.70.</th>\n","      <th>ANKLE Power_X_MAX_ST_time..35.70.</th>\n","      <th>HIP Moment_X_MAX_ST</th>\n","      <th>HIP Moment_X_MAX_ST_time</th>\n","      <th>HIP Moment_X_MAX_SW</th>\n","      <th>HIP Moment_X_MAX_SW_time</th>\n","      <th>HIP Moment_X_MIN_ST..35.70.</th>\n","      <th>HIP Moment_X_MIN_ST_time..35.70.</th>\n","      <th>...</th>\n","      <th>KNEE Moment_X_MAX_ST_time..12.35.</th>\n","      <th>KNEE Moment_X_MAX_ST..35.70.</th>\n","      <th>KNEE Moment_X_MAX_ST_time..35.70.</th>\n","      <th>KNEE Power_X_MIN_SW</th>\n","      <th>KNEE Power_X_MIN_SW_time</th>\n","      <th>KNEE Power_X_MAX_ST..12.35.</th>\n","      <th>KNEE Power_X_MAX_ST_time..12.35.</th>\n","      <th>KNEE Power_X_MIN_ST_time..01.25.</th>\n","      <th>KNEE Power_X_MIN_ST..35.70.</th>\n","      <th>KNEE Power_X_MIN_ST_time..35.70.</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.6513</td>\n","      <td>50.435</td>\n","      <td>4.4286</td>\n","      <td>55.652</td>\n","      <td>0.22744</td>\n","      <td>0.86957</td>\n","      <td>0.35350</td>\n","      <td>94.783</td>\n","      <td>-0.91131</td>\n","      <td>51.304</td>\n","      <td>...</td>\n","      <td>13.043</td>\n","      <td>0.26139</td>\n","      <td>57.391</td>\n","      <td>-1.05230</td>\n","      <td>93.043</td>\n","      <td>0.31687</td>\n","      <td>22.609</td>\n","      <td>9.5652</td>\n","      <td>-1.0244</td>\n","      <td>57.391</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.5483</td>\n","      <td>50.000</td>\n","      <td>4.5833</td>\n","      <td>56.140</td>\n","      <td>0.52977</td>\n","      <td>5.26320</td>\n","      <td>0.39082</td>\n","      <td>97.368</td>\n","      <td>-0.73814</td>\n","      <td>54.386</td>\n","      <td>...</td>\n","      <td>12.281</td>\n","      <td>0.30982</td>\n","      <td>57.018</td>\n","      <td>-1.59600</td>\n","      <td>92.982</td>\n","      <td>0.37378</td>\n","      <td>14.035</td>\n","      <td>9.6491</td>\n","      <td>-1.4494</td>\n","      <td>57.018</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.2021</td>\n","      <td>45.455</td>\n","      <td>2.9617</td>\n","      <td>52.525</td>\n","      <td>0.50208</td>\n","      <td>6.06060</td>\n","      <td>0.42453</td>\n","      <td>91.919</td>\n","      <td>-1.05820</td>\n","      <td>47.475</td>\n","      <td>...</td>\n","      <td>12.121</td>\n","      <td>0.50550</td>\n","      <td>53.535</td>\n","      <td>-1.11660</td>\n","      <td>88.889</td>\n","      <td>0.60614</td>\n","      <td>16.162</td>\n","      <td>8.0808</td>\n","      <td>-2.1391</td>\n","      <td>54.545</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.3666</td>\n","      <td>46.000</td>\n","      <td>3.2444</td>\n","      <td>53.000</td>\n","      <td>0.62291</td>\n","      <td>5.00000</td>\n","      <td>0.54590</td>\n","      <td>95.000</td>\n","      <td>-1.13550</td>\n","      <td>48.000</td>\n","      <td>...</td>\n","      <td>15.000</td>\n","      <td>0.38262</td>\n","      <td>53.000</td>\n","      <td>-1.47290</td>\n","      <td>90.000</td>\n","      <td>0.29247</td>\n","      <td>15.000</td>\n","      <td>8.0000</td>\n","      <td>-1.3109</td>\n","      <td>55.000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.4126</td>\n","      <td>46.903</td>\n","      <td>3.2861</td>\n","      <td>53.982</td>\n","      <td>0.22335</td>\n","      <td>4.42480</td>\n","      <td>0.22118</td>\n","      <td>95.575</td>\n","      <td>-0.50891</td>\n","      <td>53.097</td>\n","      <td>...</td>\n","      <td>12.389</td>\n","      <td>0.30479</td>\n","      <td>54.867</td>\n","      <td>-0.85151</td>\n","      <td>90.265</td>\n","      <td>0.79264</td>\n","      <td>14.159</td>\n","      <td>8.8496</td>\n","      <td>-1.1395</td>\n","      <td>55.752</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 32 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d012e966-e362-4b75-8eb1-7316cab734c3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d012e966-e362-4b75-8eb1-7316cab734c3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d012e966-e362-4b75-8eb1-7316cab734c3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"_VfdqPx7nNxR","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1663253268439,"user_tz":180,"elapsed":164,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"e5ef7cfb-7d67-4dbe-f10a-373febba4fd1"},"source":["temp = pd.DataFrame(segments[\"KINETICS\"].keys().to_numpy(), columns=[\"FeatureNames\"])\n","\n","features = temp.iloc[sfs_feature_idx]\n","features"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                          FeatureNames\n","0        ANKLE Moment_X_MAX_ST..35.70.\n","1   ANKLE Moment_X_MAX_ST_time..35.70.\n","2         ANKLE Power_X_MAX_ST..35.70.\n","3    ANKLE Power_X_MAX_ST_time..35.70.\n","4                  HIP Moment_X_MAX_ST\n","5             HIP Moment_X_MAX_ST_time\n","6                  HIP Moment_X_MAX_SW\n","7             HIP Moment_X_MAX_SW_time\n","8          HIP Moment_X_MIN_ST..35.70.\n","9     HIP Moment_X_MIN_ST_time..35.70.\n","10         HIP Moment_Y_MAX_ST..12.35.\n","11    HIP Moment_Y_MAX_ST_time..12.35.\n","12         HIP Moment_Y_MAX_ST..35.70.\n","13    HIP Moment_Y_MAX_ST_time..35.70.\n","14          HIP Power_X_MAX_ST..12.35.\n","15     HIP Power_X_MAX_ST_time..12.35.\n","16          HIP Power_X_MAX_ST..35.70.\n","18          HIP Power_X_MIN_ST..35.70.\n","19     HIP Power_X_MIN_ST_time..35.70.\n","20                KNEE Moment_X_MIN_ST\n","21           KNEE Moment_X_MIN_ST_time\n","22        KNEE Moment_X_MAX_ST..12.35.\n","23   KNEE Moment_X_MAX_ST_time..12.35.\n","24        KNEE Moment_X_MAX_ST..35.70.\n","25   KNEE Moment_X_MAX_ST_time..35.70.\n","26                 KNEE Power_X_MIN_SW\n","27            KNEE Power_X_MIN_SW_time\n","28         KNEE Power_X_MAX_ST..12.35.\n","29    KNEE Power_X_MAX_ST_time..12.35.\n","31    KNEE Power_X_MIN_ST_time..01.25.\n","32         KNEE Power_X_MIN_ST..35.70.\n","33    KNEE Power_X_MIN_ST_time..35.70."],"text/html":["\n","  <div id=\"df-49129f06-dd85-4ab6-9806-0f7f13ac5818\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>FeatureNames</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ANKLE Moment_X_MAX_ST..35.70.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ANKLE Moment_X_MAX_ST_time..35.70.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ANKLE Power_X_MAX_ST..35.70.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ANKLE Power_X_MAX_ST_time..35.70.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>HIP Moment_X_MAX_ST</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>HIP Moment_X_MAX_ST_time</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>HIP Moment_X_MAX_SW</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>HIP Moment_X_MAX_SW_time</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>HIP Moment_X_MIN_ST..35.70.</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>HIP Moment_X_MIN_ST_time..35.70.</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>HIP Moment_Y_MAX_ST..12.35.</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>HIP Moment_Y_MAX_ST_time..12.35.</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>HIP Moment_Y_MAX_ST..35.70.</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>HIP Moment_Y_MAX_ST_time..35.70.</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>HIP Power_X_MAX_ST..12.35.</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>HIP Power_X_MAX_ST_time..12.35.</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>HIP Power_X_MAX_ST..35.70.</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>HIP Power_X_MIN_ST..35.70.</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>HIP Power_X_MIN_ST_time..35.70.</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>KNEE Moment_X_MIN_ST</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>KNEE Moment_X_MIN_ST_time</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>KNEE Moment_X_MAX_ST..12.35.</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>KNEE Moment_X_MAX_ST_time..12.35.</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>KNEE Moment_X_MAX_ST..35.70.</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>KNEE Moment_X_MAX_ST_time..35.70.</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>KNEE Power_X_MIN_SW</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>KNEE Power_X_MIN_SW_time</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>KNEE Power_X_MAX_ST..12.35.</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>KNEE Power_X_MAX_ST_time..12.35.</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>KNEE Power_X_MIN_ST_time..01.25.</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>KNEE Power_X_MIN_ST..35.70.</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>KNEE Power_X_MIN_ST_time..35.70.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49129f06-dd85-4ab6-9806-0f7f13ac5818')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-49129f06-dd85-4ab6-9806-0f7f13ac5818 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-49129f06-dd85-4ab6-9806-0f7f13ac5818');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"Qep9E9ape2nl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663253448784,"user_tz":180,"elapsed":179434,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"ca840360-91bd-458c-d9f9-e755830dcece"},"source":["from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n","from utils import *\n","\n","for (key, value) in segments.items():\n","  print(\"Running: \", key)\n","\n","  X = value.iloc[:, sfs_feature_idx].values\n","  X = sc.fit_transform(X) # Standard Scaler\n","  print(\"X.shape = \", X.shape)\n","\n","  search_results = gridSearch.fit(X, y)\n","  \n","  # Get the Best Classfier (Best Parameters) after Grid Search\n","  best_classifier = search_results.best_estimator_\n","  print(\"best_classifier = \", best_classifier)\n","  \n","  # Apply LOOCV to get classification scores\n","  y_true_list, y_pred_list = [], []\n","  for train_idx, test_idx in loocv.split(X, y):\n","      x_train, y_train = X[train_idx], y[train_idx]\n","      x_test, y_test = X[test_idx], y[test_idx]\n","      \n","      best_classifier.fit(x_train, y_train)\n","      \n","      y_pred = best_classifier.predict(x_test)\n","\n","      y_true_list.append(y_test[:])\n","      y_pred_list.append(y_pred[:])\n","\n","  print(\"\\n##############################################################\\n\")\n","\n","  print(\"{}, {}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}, {:.3f}\".format(algorith_you_are_using, \n","                                                                                          key, \n","                                                                                          accuracy_score(y_true_list, y_pred_list),\n","                                                                                          get_specificity(y_true_list, y_pred_list),\n","                                                                                          get_sensitivity(y_true_list, y_pred_list),\n","                                                                                          get_NPV(y_true_list, y_pred_list),\n","                                                                                          get_PPV(y_true_list, y_pred_list),\n","                                                                                          get_PLR(y_true_list, y_pred_list),\n","                                                                                          f1_score(y_true_list, y_pred_list, labels=[0, 1]),\n","                                                                                          get_MCC(y_true_list, y_pred_list)                                                                                               \n","                                                                                          ))\n","\n","  print(\"\\n##############################################################\")"],"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Running:  KINETICS\n","X.shape =  (72, 32)\n","Fitting 72 folds for each of 912 candidates, totalling 65664 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n","5472 fits failed out of a total of 65664.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","5472 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 255, in fit\n","    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n","  File \"/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py\", line 333, in _dense_fit\n","    random_seed=random_seed,\n","  File \"sklearn/svm/_libsvm.pyx\", line 189, in sklearn.svm._libsvm.fit\n","ValueError: C <= 0\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889 0.63888889\n"," 0.63888889 0.63888889 0.63888889 0.63888889 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111 0.73611111\n"," 0.73611111 0.73611111        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n","        nan        nan        nan        nan        nan        nan\n"," 0.84722222 0.83333333 0.83333333 0.83333333 0.84722222 0.83333333\n"," 0.83333333 0.83333333 0.84722222 0.83333333 0.83333333 0.83333333\n"," 0.84722222 0.83333333 0.83333333 0.83333333 0.84722222 0.83333333\n"," 0.83333333 0.83333333 0.84722222 0.83333333 0.83333333 0.83333333\n"," 0.84722222 0.83333333 0.83333333 0.83333333 0.84722222 0.83333333\n"," 0.83333333 0.83333333 0.84722222 0.83333333 0.83333333 0.83333333\n"," 0.84722222 0.83333333 0.83333333 0.83333333 0.84722222 0.83333333\n"," 0.83333333 0.83333333 0.84722222 0.83333333 0.83333333 0.83333333\n"," 0.84722222 0.83333333 0.83333333 0.83333333 0.84722222 0.83333333\n"," 0.83333333 0.83333333 0.84722222 0.83333333 0.83333333 0.83333333\n"," 0.84722222 0.83333333 0.83333333 0.83333333 0.84722222 0.83333333\n"," 0.83333333 0.83333333 0.84722222 0.83333333 0.83333333 0.83333333\n"," 0.84722222 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333 0.83333333\n"," 0.83333333 0.83333333 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.90277778 0.90277778 0.90277778 0.91666667 0.90277778\n"," 0.90277778 0.90277778 0.91666667 0.90277778 0.90277778 0.90277778\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667\n"," 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667 0.91666667]\n","  category=UserWarning,\n"]},{"output_type":"stream","name":"stdout","text":["best_classifier =  SVC(C=2, kernel='linear', tol=0.01)\n","\n","##############################################################\n","\n","LinearSVM, KINETICS, 0.917, 0.917, 0.917, 0.917, 0.917, 11.000, 0.917, 0.833\n","\n","##############################################################\n"]}]},{"cell_type":"code","metadata":{"id":"BcdmtDTJe3_a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663253448784,"user_tz":180,"elapsed":13,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"f94135fc-1883-40ce-c3b4-d1f9240983e6"},"source":["search_results.best_params_"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'C': 2, 'gamma': 'scale', 'kernel': 'linear', 'tol': 0.01}"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"z23sgafFh0Iq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663253448784,"user_tz":180,"elapsed":10,"user":{"displayName":"Deepakraja R","userId":"15920242286439960751"}},"outputId":"ce5b5b3b-1d50-443d-f971-967dd728cc39"},"source":["search_results.best_score_"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9166666666666666"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":[],"metadata":{"id":"g-pz33tScx8g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xBRLrdNtcx3Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GHTnaK5Mcxwq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"F9CVK5jGelKL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"a3Fl1NCgelDo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##############################################################################\n","//////////////////////////////////////////////////////////////////////////////\n","##############################################################################"],"metadata":{"id":"BkEYdgfKcxqh"},"execution_count":null,"outputs":[]}]}